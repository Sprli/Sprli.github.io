<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="https://sprli.github.io/atom.xml" rel="self"/>
  
  <link href="https://sprli.github.io/"/>
  <updated>2023-06-23T13:41:56.148Z</updated>
  <id>https://sprli.github.io/</id>
  
  <author>
    <name>李祖乐</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>GitHub操作常用指令</title>
    <link href="https://sprli.github.io/2023/06/19/github_command/"/>
    <id>https://sprli.github.io/2023/06/19/github_command/</id>
    <published>2023-06-19T13:00:47.859Z</published>
    <updated>2023-06-23T13:41:56.148Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>git config --global</p></li><li><p>git pull origin main<br>保持本地与GitHub仓库内容一致</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;git config --global&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;git pull origin main&lt;br&gt;
保持本地与GitHub仓库内容一致&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>关于在Jetson部署Yolov5实现检测与串口通信传送位置信息</title>
    <link href="https://sprli.github.io/2023/06/14/ocean_competC2/"/>
    <id>https://sprli.github.io/2023/06/14/ocean_competC2/</id>
    <published>2023-06-14T03:27:11.440Z</published>
    <updated>2023-07-06T04:19:47.511Z</updated>
    
    <content type="html"><![CDATA[<p>这篇博客用来记录参加海赛C2过程中，如何实现在Jetson Nano上部署目标检测算法以及使用串口通信的方法。</p><h3 id="数据标注与模型训练">数据标注与模型训练</h3><h4 id="YoloV5的使用与简单讲解">YoloV5的使用与简单讲解</h4><p>Yolov5模型目前在网络上已经经过了许多考验，且其Github官方也仍在不断更新，其相关平台的部署在官网也有很多教程，所以如果想在嵌入式平台部署目标检测以及分类网络，选择Yolov5可以带给我们极大的便利，这也是我选择使用Yolov5的原因。以下内容都是基于Yolov5目标检测模型的部署。</p><h4 id="数据集的标注（使用Labelimg进行数据标注）">数据集的标注（使用Labelimg进行数据标注）</h4><ol><li><p>安装labelimg<br>这里是在Anaconda环境下的安装</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">conda create -n label python&#x3D;&#x3D;3.9 # 注意这里必须是python3.9版本，否则安装会导致无法正常使用conda activate label # 激活环境pip install labelimg # 使用pip安装labelimglabelimg # 这是打开labelimg界面的指令<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>打开labelimg并配置信息<br>输入命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">labelimg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>之后会进入如下界面<br><img src="/images/OceanC2/1.png" style="zoom: 100%;" /></p><ul><li>这里主要需要配置上图中三个红圈选项<br>先简单介绍一下：<ul><li>Open Dir：这里是打开你存放图片的文件夹</li><li>Change Save Dir：这里是你图片标注的标签数据存放位置</li><li>Yolo：这个是选择标注数据的格式，其中有很多个选项，根据自己模型训练所需的标签类型进行选择，这里选择yolo因为我训练的数据标签要求是Yolo类型。</li></ul></li></ul></li><li><p>进行数据标注<br>当把上述配置准备工作完成后，就可以开始数据标注了啦，如下视频所示：<br><video id="video" controls="" preload="none" poster="封面"><br><source id="mp4" src="/videos/labelimg_video1.mp4" type="video/mp4"><br></videos><br>如上视频所示，对数据进行标注。这里介绍最常使用的快捷键，可以帮助更快地进行数据标注工作：</p><ul><li>W键：显示十字光标，出现十字光标后即可配合鼠标框住目标</li><li>D键：下一张图片</li><li>A键：上一张图片</li><li>Ctrl+S键：对当前操作进行保存</li><li>Ctrl+鼠标滚轮：对图片上鼠标所指区域进行放大和缩小操作<br>一般来说，知道上述四种快捷键即可帮助你进行快捷标注数据啦</li></ul></li></ol><h4 id="进行训练">进行训练</h4><p>在标注完数据后，剩下的就是核心环节：训练模型</p><ol><li><p>下载官方源码<br>首先从Yolov5官方Github上clone其代码：<a href="https://github.com/ultralytics/yolov5">https://github.com/ultralytics/yolov5</a><br>可以使用两种方式下载其代码：</p><ul><li><p>方法一：使用git clone命令下载：<br><img src="/images/OceanC2/2.png" style="zoom: 100%;" /><br>如上图所示，copy当前github下载链接，然后在你的虚拟环境下输入命令：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">git clone git@github.com:ultralytics&#x2F;yolov5.git  # 这条指令会在你的当前路径下载Yolov5文件<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果失败了，显示没有找到git命令，那么就是当前你的虚拟环境没有安装git，使用conda install git 或者 pip install git命令进行安装<br>如果失败了，显示是网络问题，那么可能你需要挂梯子才可以。如果仍然无法解决，那么就尝试开关重启。</p></li><li><p>方法二：直接从官网下载zip文件：<br><img src="/images/OceanC2/3.png" style="zoom: 100%;" /><br>如上图所示，点击红圈选项，下载zip文件，随后将其解压即可得到Yolov5官方文件</p></li></ul></li><li><p>配置模型训练相关信息<br>然后进入文件目录，在data文件夹下创建一个C2.yaml文件，其内容如下：</p> <pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"># YOLOv5 🚀 by Ultralytics, AGPL-3.0 license# COCO128 dataset https:&#x2F;&#x2F;www.kaggle.com&#x2F;ultralytics&#x2F;coco128 (first 128 images from COCO train2017) by Ultralytics# Example usage: python train.py --data coco128.yaml# parent# ├── yolov5# └── datasets#     └── coco128  ← downloads here (7 MB)# Train&#x2F;val&#x2F;test sets as 1) dir: path&#x2F;to&#x2F;imgs, 2) file: path&#x2F;to&#x2F;imgs.txt, or 3) list: [path&#x2F;to&#x2F;imgs1, path&#x2F;to&#x2F;imgs2, ..]path: ..&#x2F;datasets&#x2F;coco128  # dataset root dirtrain: images&#x2F;train2017  # train images (relative to &#39;path&#39;) 128 imagesval: images&#x2F;train2017  # val images (relative to &#39;path&#39;) 128 imagestest:  # test images (optional)# Classesnames:  0: hole<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>文件路径以及内容详细参考以下图片：<br><img src="/images/OceanC2/5.png" style="zoom: 100%;" /><br>其中：</p><ul><li>path：是指根目录的路径</li><li>train：是指要训练的图片存放位置</li><li>val：是指要验证的图片存放位置（这里和train保持一致即可）</li><li>name：类别存放位置，如图中所示：0表示目标类别索引（从0开始），hole表示其代表的类别名称</li></ul><p>这里再附上一张训练数据存放的文件夹路径及内容：<br><img src="/images/OceanC2/6.png" style="zoom:100%;" /><br>这里只需要关注白色圈中的两个文件夹dataset与yolov5，其中路径相对位置如下：</p> <pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"># parent# ├── yolov5# └── datasets#     └── coco128#         └── images#             └── train2017 # 文件夹下是训练图片#         └── labels#             └── train2017 # 文件夹下是训练图片对应的标注文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>之后按照官方文档进行配置你的虚拟环境，配置完成后即可使用终端在当前路径下输入以下命令进行训练：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">python train.py --data C2.yaml --weights yolov5n.pt --cfg yolov5n.yaml --img 640  --batch-size 4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>指令解释：</p><ul><li>–data：C2.yaml为前面所创建的文件，里面存放的是配置训练数据的相关内容</li><li>–weights： yolov5n.pt是指使用官方的yolov5n预训练模型来进行迁移学习训练</li><li>–cfg：yolov5n.yaml文件时模型的结构文件</li><li>–img：640是指送进模型进行训练的图片尺寸，640表示640x640。注意此数字应为32的整数倍，不然训练会出错</li><li>–batch-size：4是指一次送入模型训练的图片个数为4，这一项和你的GPU性能相联系，batch-size过大会导致你的GPU因为显存不够而无法训练。</li></ul><p>如果上述命令输入后显示错误，一般来说是你的batch-size设置过大了，调小即可，如2或1。<br>当然还有一个前提是，你按照官方文档成功配置好了你的虚拟环境，如pytorch、cuda等。</p><p>训练完成后，你的模型存放在如下路径：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"># parent# ├── yolov5#     └── runs#         └── train#             └── exp # 不一定是exp，也有可能是exp+一个数字#                 └── weights#                     └── best.pt # 这是训练得到的最优的权重<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="安装ros，以进行串口通信">安装ros，以进行串口通信</h3><p>这里先附上jetson nano的引脚图<br><img src="/images/OceanC2/7.png" style="zoom:100%;" /></p><h4 id="首先进行换源">首先进行换源</h4><ol><li>备份源，防止操作错误以复用<br><code>cp /etc/apt/sources.list   /etc/apt/sources.list.bak</code></li><li>编辑源文件，添加镜像<br><code>sudo gedit /etc/apt/sources.list</code></li><li>在打开的源文件中，将原内容删除，然后添加以下内容：</li></ol><ul><li>清华源：<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu-ports&#x2F; bionic main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu-ports&#x2F; bionic main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu-ports&#x2F; bionic-updates main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu-ports&#x2F; bionic-updates main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu-ports&#x2F; bionic-backports main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu-ports&#x2F; bionic-backports main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu-ports&#x2F; bionic-security main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu-ports&#x2F; bionic-security main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu-ports&#x2F; bionic-proposed main restricted universe multiversedeb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu-ports&#x2F; bionic-proposed main restricted universe multiverse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>中科大源：<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;ubuntu-ports bionic main restricted universe multiverse# deb-src http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;ubuntu-ports bionic main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;ubuntu-ports bionic-updates main restricted universe multiverse# deb-src http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;ubuntu-ports bionic-updates main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;ubuntu-ports bionic-backports main restricted universe multiverse# deb-src http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;ubuntu-ports bionic-backports main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;ubuntu-ports bionic-security main restricted universe multiverse# deb-src http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;ubuntu-ports bionic-security main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;ubuntu-ports bionic-proposed main restricted universe multiversedeb-src http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;ubuntu-ports bionic-proposed main restricted universe multiverse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>阿里源：<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu-ports&#x2F; bionic main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu-ports&#x2F; bionic main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu-ports&#x2F; bionic-updates main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu-ports&#x2F; bionic-updates main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu-ports&#x2F; bionic-backports main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu-ports&#x2F;s bionic-backports main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu-ports&#x2F; bionic-security main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu-ports&#x2F; bionic-security main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu-ports&#x2F; bionic-proposed main restricted universe multiversedeb-src https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu-ports&#x2F; bionic-proposed main restricted universe multiverse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><ol start="4"><li>添加完成后，保存并退出。使用下述两条命令更新： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> update<span class="token function">sudo</span> <span class="token function">apt</span> upgrade <span class="token parameter variable">-y</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li>更换ROS的国内源（两条指令差不多，第一个是国外，第二个是中科大的源，选择一个即可） <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">sh</span> <span class="token parameter variable">-c</span> <span class="token string">'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">sh</span> <span class="token parameter variable">-c</span> <span class="token string">'. /etc/lsb-release &amp;&amp; echo "deb http://mirrors.ustc.edu.cn/ros/ubuntu/ `lsb_release -cs` main" > /etc/apt/sources.list.d/ros-latest.list'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>然后再使用如下命令更新，完成后即配置成功 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> update<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><h4 id="获取密钥">获取密钥</h4><p>有两种方法，推荐方法一</p><ul><li>方法一：官网操作<br>可以获取最新的密钥，不用担心密钥是否过期，但可能受网络影响  <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> <span class="token function">curl</span>        <span class="token comment"># 如果你没有安装curl的话，就使用这条命令</span><span class="token function">curl</span> <span class="token parameter variable">-s</span> https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> -<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li>方法二：网络教程<br>密钥可能过期，可以到网上搜索其他人发的密钥，试一试<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> apt-key adv <span class="token parameter variable">--keyserver</span> keyserver.ubuntu.com --recv-keys 8D5A09DC9B929006<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul><p>然后再使用如下命令对源软件列表进行更新（原先可能没密钥导致更新失败）</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> update<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="安装ROS">安装ROS</h4><ol><li>安装全功能的ROS，这个安装包大概超过200M，执行以下命令：<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> ros-melodic-desktop-full<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>设置环境变量 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token string">"source /opt/ros/melodic/setup.bash"</span> <span class="token operator">>></span> ~/.bashrc<span class="token builtin class-name">source</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li>安装相关的依赖 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> python-rosdep python-rosinstall python-rosinstall-generator python-wstool build-essential  <span class="token function">vim</span> openconnect openssh-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>ROS初始化<br>使用如下命令： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> rosdeprosdep update<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li>ROS运行测试<br>在终端分别执行以下语句，测试小乌龟（具体作用我也不懂），只要能成功运行，那么表明你的ROS安装成功。 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">roscorerosrun turtlesim turtlesim_noderosrun turtlesim turtle_teleop_key<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><p>如果出现 Command rosrun not found 即 rosrun 命令找不到的情况，输入以下命令即可：<br><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> rosbash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><h4 id="删除卸载ROS">删除卸载ROS</h4><p>当发现自己安装失败无法解决时，可以尝试重新开始，那么就需要把ROS重新装一遍了。</p><ul><li>输入以下命令进行ROS的删除卸载：  <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> purge ros-*<span class="token function">sudo</span> <span class="token function">rm</span> <span class="token parameter variable">-rf</span> /etc/rosgedit ~/.bashrc   <span class="token comment"># 打开该文件，删除带有melodic那一行即可</span><span class="token builtin class-name">source</span> ~/.bashrc  <span class="token comment"># 刷新环境</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h4 id="可能遇到的问题报错">可能遇到的问题报错</h4><ol><li>Could not find a package configuration file provided by “serial“ with any serialConfig.cmake<ul><li>输入以下命令 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> ros-melodic-serial<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul></li><li>无法定位功能包 E: Unable to locate package ros-melodic-***<ul><li>方案一：首先使用以下命令更新一下，然后再次安装   <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> update<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>方案二：如果仍然无法下载，尝试输入以下命令，然后再次安装 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">sh</span> <span class="token parameter variable">-c</span> <span class="token string">'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'</span><span class="token function">sudo</span> apt-key adv <span class="token parameter variable">--keyserver</span> <span class="token string">'hkp://keyserver.ubuntu.com:80'</span> --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654<span class="token function">sudo</span> <span class="token function">apt</span> update<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li>方案三：进行换源<ul><li>再次打开sources.list文件，使用以下命令：<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> gedit /etc/apt/sources.list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>在文件末尾加入以下内容:<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">deb http://packages.ros.org/ros-shadow-fixed/ubuntu bionic main  <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>然后再次使用以下命令更新完后，再次安装：<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> update<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul></li></ul></li><li>sudo rosdep init 找不到命令<ul><li>首先查看rosdep是否安装，使用以下命令：<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">whereis</span> rosdep<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>若没有显示任何信息，则表示没有安装，然后输入以下命令进行安装rosdep：<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> python-rosdep2 <span class="token parameter variable">-y</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul></li></ol><h3 id="将模型部署在Jetson-nano上">将模型部署在Jetson nano上</h3><h4 id="模型权重的文件类型转换">模型权重的文件类型转换</h4><ol><li>将模型权重由pt格式转换为wts格式</li></ol><ul><li>在yolov5文件夹中创建一个gen_wts.py文件，内容如下：<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">import sysimport argparseimport osimport structimport torchfrom utils.torch_utils import select_devicedef parse_args():    parser &#x3D; argparse.ArgumentParser(description&#x3D;&#39;Convert .pt file to .wts&#39;)    parser.add_argument(&#39;-w&#39;, &#39;--weights&#39;, required&#x3D;True,                        help&#x3D;&#39;Input weights (.pt) file path (required)&#39;)    parser.add_argument(        &#39;-o&#39;, &#39;--output&#39;, help&#x3D;&#39;Output (.wts) file path (optional)&#39;)    parser.add_argument(        &#39;-t&#39;, &#39;--type&#39;, type&#x3D;str, default&#x3D;&#39;detect&#39;, choices&#x3D;[&#39;detect&#39;, &#39;cls&#39;, &#39;seg&#39;],        help&#x3D;&#39;determines the model is detection&#x2F;classification&#39;)    args &#x3D; parser.parse_args()    if not os.path.isfile(args.weights):        raise SystemExit(&#39;Invalid input file&#39;)    if not args.output:        args.output &#x3D; os.path.splitext(args.weights)[0] + &#39;.wts&#39;    elif os.path.isdir(args.output):        args.output &#x3D; os.path.join(            args.output,            os.path.splitext(os.path.basename(args.weights))[0] + &#39;.wts&#39;)    return args.weights, args.output, args.typept_file, wts_file, m_type &#x3D; parse_args()print(f&#39;Generating .wts for &#123;m_type&#125; model&#39;)# Load modelprint(f&#39;Loading &#123;pt_file&#125;&#39;)device &#x3D; select_device(&#39;cpu&#39;)model &#x3D; torch.load(pt_file, map_location&#x3D;device)  # Load FP32 weightsmodel &#x3D; model[&#39;ema&#39; if model.get(&#39;ema&#39;) else &#39;model&#39;].float()if m_type in [&#39;detect&#39;, &#39;seg&#39;]:    # update anchor_grid info    anchor_grid &#x3D; model.model[-1].anchors * model.model[-1].stride[..., None, None]    # model.model[-1].anchor_grid &#x3D; anchor_grid    delattr(model.model[-1], &#39;anchor_grid&#39;)  # model.model[-1] is detect layer    # The parameters are saved in the OrderDict through the &quot;register_buffer&quot; method, and then saved to the weight.    model.model[-1].register_buffer(&quot;anchor_grid&quot;, anchor_grid)    model.model[-1].register_buffer(&quot;strides&quot;, model.model[-1].stride)model.to(device).eval()print(f&#39;Writing into &#123;wts_file&#125;&#39;)with open(wts_file, &#39;w&#39;) as f:    f.write(&#39;&#123;&#125;\n&#39;.format(len(model.state_dict().keys())))    for k, v in model.state_dict().items():        vr &#x3D; v.reshape(-1).cpu().numpy()        f.write(&#39;&#123;&#125; &#123;&#125; &#39;.format(k, len(vr)))        for vv in vr:            f.write(&#39; &#39;)            f.write(struct.pack(&#39;&gt;f&#39;, float(vv)).hex())        f.write(&#39;\n&#39;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>然后在你的虚拟环境下运行如下命令：<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">python gen_wts.py -w .&#x2F;runs&#x2F;train&#x2F;exp&#x2F;weights&#x2F;best.pt -o .&#x2F;best.wts -t detect<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>命令解释：<ul><li>-w：是权重权重存放位置</li><li>-o：是生成的wts类型权重的名称以及存放路径</li><li>-t：是指定你的模型类型，detect表示目标检测网络，cls表示分类网络，seg表示分割网络<br>运行完毕后即可发现在当前路径下以及生成了一个best.wts文件</li></ul></li></ul><ol start="2"><li>将wts格式权重转换为tensorrt的engine格式<br>这里需要使用Github上开源的相关工程文件，使用git clone将工程克隆到任意路径下，需要注意的是接下来的操作都是在Jetson系统上进行的。<ul><li>下载相关文件，使用命令（方法同上）：  <pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">git clone https:&#x2F;&#x2F;github.com&#x2F;wang-xinyu&#x2F;tensorrtx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>该工程目录如下： <pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"># ├── tensorrtx#     └── yolov5#         └── images#         └── best.wts # 将上述生成得到的best.wts文件放入此路径#         └── plugin # 里面存放的适合yolov5模型结构相关的文件#         └── src # 里面是我们需要修改到的模型运行配置文件#             └── config.h#                 └── weights#                     └── best.pt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>修改细节如下：<ul><li>config.h：将其中的kNumClass = 80修改为我们模型训练使用的类别数，这里我修改的kNumClass = 2;</li></ul></li><li>然后在yolov5路径下使用如下命令将wts格式权重文件转换为engine格式权重文件 <pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">mkdir buildcd buildcmake ..makesudo .&#x2F;yolov5_det -s ..&#x2F;best.wts ..&#x2F;best.engine n<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>命令解释：<ul><li>前四行命令：是使用cmake相关指令对相关文件进行编译，以生成可执行文件yolov5_det</li><li>最后一行命令：<ul><li>yolov5_det：目标检测的可执行文件，yolov5_cls与yolov5_seg同理；</li><li>-s：应该是一种模型选择（即选择进行模型转换模型），…/best.wts表示我们前面操作生成的wts格式权重文件，即源文件；…/best.engine是目标文件，即生成转换得到的文件</li><li>n：是我们yolov5模型的类型，这里由于我选择使用的是yolov5n模型，故为n。这里拓展一下若是yolov5m模型，则是m；yolov5l模型，则是l；其他类型同理即可。<br>注意：如果运行失败，请严格对照是否按照上述操作对相关文件进行修改。</li></ul></li></ul></li><li>之后使用如下命令检验生成的engine文件是否有问题： <pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">sudo .&#x2F;yolov5_det -d ..&#x2F;best.engine ..&#x2F;samples<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>命令解释：<ul><li>-d：解释同上，是一种模型选择，即进行测试</li><li>…/best.engine：我们生成的engine格式文件路径</li><li>…/samples：我们要检测的图片存放路径，这里可自行创建该文件夹，并将自己的图片放入此文件夹</li></ul></li><li>运行完后，会在当前路径下得到检测后的图片，可以自行观察检测模型是否有问题。</li><li>相关路径： <pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"># ├── tensorrtx#     └── yolov5#         └── images#         └── best.wts # 将上述生成得到的best.wts文件放入此路径#         └── best.engine # 生成的engine文件#         └── samples#             └── test1.jpg#             └── test2.jpg#             └── ...#         └── plugin # 里面存放的适合yolov5模型结构相关的文件#         └── src # 里面是我们需要修改到的模型运行配置文件#             └── config.h#                 └── weights#                     └── best.pt#         └── build # cmake相关语句后得到的文件#             └── yolov5_det#             └── libmyplugins.so<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li></ol><h4 id="选择框架——DeepStream">选择框架——DeepStream</h4><ol><li>安装Deepstream5.x<ul><li>附上下载地址：<a href="https://developer.nvidia.com/deepstream-getting-started">https://developer.nvidia.com/deepstream-getting-started</a></li><li>这里需要注意的是必须安装Deepstream5.x版本，最好是5.0，不然以下操作可能无效，</li></ul></li><li>下载相关源文件<br>从Github上克隆他人开源的工程文件，使用命令（方法同上）： <pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">git clone git@github.com:DanaHan&#x2F;Yolov5-in-Deepstream-5.0.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>该工程目录如下（这里只给出要修改的文件）： <pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"># ├── Yolov5-in-Deepstream-5.0#     └── Deepstream5.0#         └── includes#         └── nvdsinfer_custom_impl_Yolo#             └── nvdsparsebbox_Yolo.cpp#             └── Makefile#         └── deepstream_app_config_yoloV5.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>修改细节：<ul><li>进入nvdsparsebbox_Yolo.cpp文件，内容如下，细节见注释：<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">...#include &lt;cstdio&gt;#include &quot;serial&#x2F;serial.h&quot;#include &lt;vector&gt;...static bool NvDsInferParseYoloV5(    std::vector&lt;NvDsInferLayerInfo&gt; const&amp; outputLayersInfo,    NvDsInferNetworkInfo const&amp; networkInfo,    NvDsInferParseDetectionParams const&amp; detectionParams,    std::vector&lt;NvDsInferParseObjectInfo&gt;&amp; objectList)&#123;        serial::Serial my_serial(&quot;&#x2F;dev&#x2F;ttyTHS1&quot;, 9600, serial::Timeout::simpleTimeout(50)); &#x2F;&#x2F; 设置串口    &#x2F;*if(my_serial.isOpen())&#123;                                                           &#x2F;&#x2F; 测试串口是否成功打开        std::cout &lt;&lt; &quot;the location:    X:&quot; &lt;&lt; std::endl;    &#125;*&#x2F;    std::vector&lt;Detection&gt; res;    nms(res, (float*)(outputLayersInfo[0].buffer), CONF_THRESH, NMS_THRESH);    &#x2F;&#x2F;std::cout&lt;&lt;&quot;Nms done sucessfully----&quot;&lt;&lt;std::endl;    NvDsInferParseObjectInfo globalbbox;                                                &#x2F;&#x2F; 设置目标检测区域    globalbbox.classId &#x3D; 0;    globalbbox.left    &#x3D; static_cast&lt;unsigned int&gt;(160);    globalbbox.top     &#x3D; static_cast&lt;unsigned int&gt;(120);    globalbbox.width   &#x3D; static_cast&lt;unsigned int&gt;(320);    globalbbox.height  &#x3D; static_cast&lt;unsigned int&gt;(240);    globalbbox.detectionConfidence &#x3D; 0.9;    objectList.push_back(globalbbox);                                                   &#x2F;&#x2F; 将目标检测区域当作目标，以在视频中得到显示    std::string output &#x3D; &quot;A&quot;;                                                           &#x2F;&#x2F; 设置标志位    unsigned int x &#x3D; 100;                                                               &#x2F;&#x2F; 设置初始目标的中心    unsigned int y &#x3D; 100;    unsigned int x_temp &#x3D; 0;                                                            &#x2F;&#x2F; 设置暂存变量    unsigned int y_temp &#x3D; 0;    double confidence_max &#x3D; 0;                                                          &#x2F;&#x2F; 按照置信度进行优先级选择    for(auto&amp; r : res) &#123;      NvDsInferParseObjectInfo oinfo;              oinfo.classId &#x3D; r.class_id;            if(oinfo.classId !&#x3D; 0) continue;      oinfo.left    &#x3D; static_cast&lt;unsigned int&gt;(r.bbox[0]-r.bbox[2]*0.5f);      oinfo.top     &#x3D; static_cast&lt;unsigned int&gt;(r.bbox[1]-r.bbox[3]*0.5f);      oinfo.width   &#x3D; static_cast&lt;unsigned int&gt;(r.bbox[2]);      oinfo.height  &#x3D; static_cast&lt;unsigned int&gt;(r.bbox[3]);      oinfo.detectionConfidence &#x3D; r.conf;      x_temp &#x3D; static_cast&lt;unsigned int&gt;(oinfo.left + oinfo.width*0.5f);                &#x2F;&#x2F; 计算目标的中心x,y      y_temp &#x3D; static_cast&lt;unsigned int&gt;(oinfo.top + oinfo.height*0.5f);      if(x_temp&gt;160 &amp;&amp; x_temp&lt;480 &amp;&amp; y_temp&gt;120 &amp;&amp; y_temp&lt; 360 &amp;&amp; r.conf &gt; confidence_max)&#123;  &#x2F;&#x2F; 判断目标中心是否落入检测区域          x &#x3D; x_temp;y &#x3D; y_temp; confidence_max &#x3D; r.conf;      &#125;      objectList.push_back(oinfo);            &#125;    output +&#x3D; std::to_string(x);                                                        &#x2F;&#x2F; 将串口要发送的位置信息转换为合适格式    output +&#x3D; std::to_string(y);    output +&#x3D; &#39;B&#39;;                                                                      &#x2F;&#x2F; 设置停止位    std::vector&lt;uint8_t&gt; data(output.begin(), output.end());                            &#x2F;&#x2F; 对数据进行编码，以配合串口发送信息    &#x2F;&#x2F; std::cout &lt;&lt; data.size() &lt;&lt; std::endl;    my_serial.write(data.data(), data.size());                                          &#x2F;&#x2F; 串口发送坐标信息    std::cout &lt;&lt; &quot;the location:    X:&quot; &lt;&lt; x &lt;&lt;&quot;,   Y:&quot; &lt;&lt; y  &lt;&lt; &quot;,   conf:&quot; &lt;&lt; confidence_max &lt;&lt; &quot;,   link:&quot; &lt;&lt; data.data() &lt;&lt; std::endl;  &#x2F;&#x2F; d打印当前串口发送的坐标信息，实际中可以将此行注释掉，因为print操作会影响程序运行速度    return true;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>将上述模型格式转换过程中生成的best.engine与libmyplugins.so文件复制到Deepstream5.0路径下</li><li>修改deepstream_app_config_yoloV5.txt文件，修改细节以及具体注释如下：<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">...[source0]enable&#x3D;1#Type - 1&#x3D;CameraV4L2 2&#x3D;URI 3&#x3D;MultiURItype&#x3D;1   # cameracamera-width&#x3D;640 # 相机获取视频的宽camera-height&#x3D;480# 相机获取视频的高camera-fps-n&#x3D;30  # 相机获取视频的帧率分子为30camera-fps-d&#x3D;1   # 相机获取视频的帧率分母为1，n与d配合，即30帧#camera-v412-dev-node&#x3D;0#uri&#x3D;file:&#x2F;opt&#x2F;nvidia&#x2F;deepstream&#x2F;deepstream-5.0&#x2F;samples&#x2F;streams&#x2F;sample_1080p_h264.mp4#uri&#x3D;file:&#x2F;home&#x2F;nvidia&#x2F;Documents&#x2F;5-Materials&#x2F;Videos&#x2F;0825.avinum-sources&#x3D;1    # 设置输入源数量，这里是1个gpu-id&#x3D;0         # 设置使用的GPU ID，这里是0号GPU# (0): memtype_device   - Memory type Device# (1): memtype_pinned   - Memory type Host Pinned# (2): memtype_unified  - Memory type Unifiedcudadec-memtype&#x3D;0  # 设置CUDA解码器使用的内存类型，这里是Device内存...# 这里是配置生成视频流[streammux] ...width&#x3D;640height&#x3D;480......[primary-gie]enable&#x3D;1gpu-id&#x3D;0model-engine-file&#x3D;best.engine # 物体检测模型引擎文件labelfile-path&#x3D;labels.txt     # 标签文件路径,包含类名，这里需要自己创建一个labels.txt文件#batch-size&#x3D;1#Required by the app for OSD, not a plugin propertybbox-border-color0&#x3D;1;0;0;1  # 边界框边框颜色bbox-border-color1&#x3D;0;1;1;1bbox-border-color2&#x3D;0;0;1;1bbox-border-color3&#x3D;0;1;0;1interval&#x3D;0  # 推理间隔,单位毫秒gie-unique-id&#x3D;1nvbuf-memory-type&#x3D;0config-file&#x3D;config_infer_primary_yoloV5.txt  # 包含更多设置的配置文件[tracker]enable&#x3D;0tracker-width&#x3D;512tracker-height&#x3D;320ll-lib-file&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;deepstream&#x2F;deepstream-5.0&#x2F;lib&#x2F;libnvds_mot_klt.so  # 根据自己的libnvds_mot_klt.so存放路径进行更改，一般而言不需要修改此项。如果是Deepstream5.1，可能需要修改为&#x2F;opt&#x2F;nvidia&#x2F;deepstream&#x2F;deepstream-5.1&#x2F;lib&#x2F;libnvds_mot_klt.so...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>在Deepstream5.0路径下创建一个labels.txt文件，内容如下：<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">hole<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>解释：一个目标一行，即表示索引和内容</li><li>修改Makefile文件内容，细节以及注释如下：<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">CUDA_VER?&#x3D;10.2ifeq ($(CUDA_VER),)  $(error &quot;CUDA_VER is not set&quot;)endifCC:&#x3D; g++NVCC:&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda-$(CUDA_VER)&#x2F;bin&#x2F;nvccCFLAGS:&#x3D; -Wall -std&#x3D;c++11 -shared -fPIC -Wno-error&#x3D;deprecated-declarationsCFLAGS+&#x3D; -I..&#x2F;includes -I&#x2F;usr&#x2F;local&#x2F;cuda-$(CUDA_VER)&#x2F;include -I&#x2F;opt&#x2F;ros&#x2F;melodic&#x2F;include # 新增的，以成功在待编译的cpp文件中引入&lt;serial&#x2F;serial.h&gt;头文件LIBS:&#x3D; -lnvinfer_plugin -lnvinfer -lnvparsers -L&#x2F;usr&#x2F;local&#x2F;cuda-$(CUDA_VER)&#x2F;lib64 -lcudart -lcublas -lstdc++fs -L&#x2F;opt&#x2F;ros&#x2F;melodic&#x2F;lib -lserial  # 新增的，链接库文件&#x2F;opt&#x2F;ros&#x2F;melodic&#x2F;lib&#x2F;libserial.so，以实现串口通信。LFLAGS:&#x3D; -shared -Wl,--start-group $(LIBS) -Wl,--end-groupINCS:&#x3D; $(wildcard *.h) SRCFILES:&#x3D; nvdsinfer_yolo_engine.cpp \          nvdsparsebbox_Yolo.cpp   \          trt_utils.cpp              \          #  yolo.cpp              \  # 注释掉这两行，因为使用不到，并且使用的话会导致无法顺利通过编译。          #  yoloPlugins.cpp          # 注释掉这两行TARGET_LIB:&#x3D; libnvdsinfer_custom_impl_Yolo.so#TARGET_LIB:&#x3D; libnvdsinfer_custom_impl_Yolo.soTARGET_OBJS:&#x3D; $(SRCFILES:.cpp&#x3D;.o)TARGET_OBJS:&#x3D; $(TARGET_OBJS:.cu&#x3D;.o)all: $(TARGET_LIB)%.o: %.cpp $(INCS) Makefile  $(CC) -c -o $@ $(CFLAGS) $&lt;%.o: %.cu $(INCS) Makefile  $(NVCC) -c -o $@ --compiler-options &#39;-fPIC&#39; $&lt;$(TARGET_LIB) : $(TARGET_OBJS)  $(CC) -o $@  $(TARGET_OBJS) $(LFLAGS)clean:  rm -rf $(TARGET_LIB)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>上述Makefile文件的修改具体解释可以参考我的另一篇博客，里面详细记录了相关内容：<a href="https://sprli.github.io/2023/05/26/Cmake_Study/">https://sprli.github.io/2023/05/26/Cmake_Study/</a></li></ul></li></ol><h4 id="运行及使用">运行及使用</h4><h3 id="如何实现程序自启动">如何实现程序自启动</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这篇博客用来记录参加海赛C2过程中，如何实现在Jetson Nano上部署目标检测算法以及使用串口通信的方法。&lt;/p&gt;
&lt;h3 id=&quot;数据标注与模型训练&quot;&gt;数据标注与模型训练&lt;/h3&gt;
&lt;h4 id=&quot;YoloV5的使用与简单讲解&quot;&gt;YoloV5的使用与简单讲解&lt;/h4&gt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>cmake学习记录</title>
    <link href="https://sprli.github.io/2023/05/26/Cmake_Study/"/>
    <id>https://sprli.github.io/2023/05/26/Cmake_Study/</id>
    <published>2023-05-26T03:48:14.194Z</published>
    <updated>2023-07-08T11:28:08.751Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题背景">问题背景</h2><p>这个问题是我在做海赛C2比赛编写部署自动打靶算法遇到的。先简单叙述一下起因，由于我们C2队伍使用的是Jetson Nano来识别靶心，进而实现自动打靶功能，于是算法识别这方面就由我来进展。在网上参考了一些部署方案。最终选择了使用Deepstream架构运行yolov5n的trt模型进行识别检测。但是由于我们的需求不仅是检测到靶心，还要将检测到的靶心的位置传递给下位机stm32，因此我需要在该架构中加入串口通信模块，实现该功能。由于Deepstream在国内的相关资料很少，故需要自己去了解并实现添加该模块到这个框架中。而且其代码基本都是C++代码，过程中要用到cmake等编译工具，故而接触到了cmake相关文件的编写与使用，并写下该篇博客对其进行记录。</p><h2 id="一、cmake是什么">一、cmake是什么</h2><p>CMake是一个跨平台的编译(Build)工具,可以用简单的语句来描述所有平台的编译过程。<br>CMake能够输出各种各样的makefile或者project文件，能测试编译器所支持的C++特性。<br>假如我们有一个深度学习框架的部分工程列表，里面有超过40个互相调用的工程共同组成，一些用于生成库文件，一些用于实现逻辑功能。他们之间的调用关系复杂而严格，如果我想在这样复杂的框架下进行二次开发，显然只拥有它的源码是远远不够的，还需要清楚的明白这几十个项目之间的复杂关系，在没有原作者的帮助下进行这项工作几乎是不可能的。即使原作者给出了相关的结构文档，对新手来说建立工程的过程依旧是漫长而艰辛的，因此CMake的作用就凸显出来了。原作者只需要生成一份CMakeLists.txt文档，框架的使用者们只需要在下载源码的同时下载作者提供的CMakeLists.txt，就可以利用CMake，在“原作者的帮助下”进行工程的搭建。</p><h2 id="二、cmake的使用">二、cmake的使用</h2><h3 id="2-1-CMakeLists-txt的语法">2.1 CMakeLists.txt的语法</h3><p>先附上相关代码</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">cmake_minimum_required(VERSION 3.10)project(yolov5)add_definitions(-std&#x3D;c++11)add_definitions(-DAPI_EXPORTS)option(CUDA_USE_STATIC_CUDA_RUNTIME OFF)set(CMAKE_CXX_STANDARD 11)set(CMAKE_BUILD_TYPE Debug)# TODO(Call for PR): make cmake compatible with Windowsset(CMAKE_CUDA_COMPILER &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;bin&#x2F;nvcc)enable_language(CUDA)include_directories(&#x2F;opt&#x2F;ros&#x2F;melodic&#x2F;include)# include and link dirs of cuda and tensorrt, you need adapt them if yours are different# cudainclude_directories(&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;include)link_directories(&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64)# tensorrt# TODO(Call for PR): make TRT path configurable from command lineinclude_directories(&#x2F;home&#x2F;nvidia&#x2F;TensorRT-8.2.5.1&#x2F;include&#x2F;)link_directories(&#x2F;home&#x2F;nvidia&#x2F;TensorRT-8.2.5.1&#x2F;lib&#x2F;)include_directories($&#123;PROJECT_SOURCE_DIR&#125;&#x2F;src&#x2F;)include_directories($&#123;PROJECT_SOURCE_DIR&#125;&#x2F;plugin&#x2F;)file(GLOB_RECURSE SRCS $&#123;PROJECT_SOURCE_DIR&#125;&#x2F;src&#x2F;*.cpp $&#123;PROJECT_SOURCE_DIR&#125;&#x2F;src&#x2F;*.cu)file(GLOB_RECURSE PLUGIN_SRCS $&#123;PROJECT_SOURCE_DIR&#125;&#x2F;plugin&#x2F;*.cu)add_library(myplugins SHARED $&#123;PLUGIN_SRCS&#125;)target_link_libraries(myplugins nvinfer cudart)find_package(OpenCV)include_directories($&#123;OpenCV_INCLUDE_DIRS&#125;)add_executable(yolov5_det yolov5_det.cpp $&#123;SRCS&#125;)target_link_libraries(yolov5_det nvinfer)target_link_libraries(yolov5_det cudart)target_link_libraries(yolov5_det myplugins)target_link_libraries(yolov5_det $&#123;OpenCV_LIBS&#125;)target_link_libraries(yolov5_det &#x2F;opt&#x2F;ros&#x2F;melodic&#x2F;lib&#x2F;libserial.so)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>相关解释：<br>由于我也是浅浅地了解使用，就只介绍我理解的几个函数吧</p><ul><li>project(yolov5) 表示定义一个名为yolov5的工程</li><li>include_directories(/opt/ros/melodic/include) 可以这样来理解，加入我们需要引入一个头文件&lt;serial/serial.h&gt;，但是这个头文件是在路径/opt/ros/melodic/include路径下，而你的文件路径却不在该路径下，如果使用#include &quot;/opt/ros/melodic/include/serial/serial.h&quot;的话未免太过麻烦了，但是如果在CmakeList.txt中加入include_directories(/opt/ros/melodic/include)一句，那么我们就可以使用#include &quot;serial/serial.h&quot;简单地引入该头文件了。</li><li>file(GLOB_RECURSE PLUGIN_SRCS ${PROJECT_SOURCE_DIR}/plugin/*.cu) 表示在项目源代码目录中的plugin子目录中查找所有扩展名为.cu的CUDA源文件，并将它们存储在PLUGIN_SRCS变量中</li><li>add_library(myplugins SHARED ${PLUGIN_SRCS}) 表示创建一个名为myplugins的共享库，并将PLUGIN_SRCS变量中的所有CUDA源文件链接到该库中。</li><li>link_directories(/home/nvidia/TensorRT-8.2.5.1/lib/) 是指将TensorRT库的路径添加到编译器的库搜索路径中，以便编译器可以找到所需的库文件</li><li>add_executable(yolov5_det yolov5_det.cpp ${SRCS}) 表示在当前路径下编译一个名为yolov5_det的可执行文件，该文件的源代码位于yolov5_det.cpp文件中，而其他源文件位于SRCS变量中。</li><li>target_link_libraries(yolov5_det /opt/ros/melodic/lib/libserial.so) 表示将名为yolov5_det的目标文件与名为libserial.so的库文件链接，以便在运行时可以使用该库文件中定义的函数和变量。</li></ul><p>明白了上面这些语句的基本用法，我们就可以在源文件的基础上加上我们的代码，实现我们想要的功能了。</p><h3 id="2-2-Makefile相关语法">2.2 Makefile相关语法</h3><p>有时候我们得到的文件中没有CMakeList.txt文件，但是会有Makefile文件，这时如果我们想修改一下代码以引入一些其他功能，也不是不可能，可以试着修改Makefile文件，尝试实现我们想要的功能。<br>先附上相关代码</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">CUDA_VER?&#x3D;ifeq ($(CUDA_VER),)$(error &quot;CUDA_VER is not set&quot;)endifOPENCV?&#x3D;ifeq ($(OPENCV),)OPENCV&#x3D;0endifCC:&#x3D; g++NVCC:&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda-$(CUDA_VER)&#x2F;bin&#x2F;nvccCFLAGS:&#x3D; -Wall -std&#x3D;c++11 -shared -fPIC -Wno-error&#x3D;deprecated-declarationsCFLAGS+&#x3D; -I&#x2F;opt&#x2F;nvidia&#x2F;deepstream&#x2F;deepstream&#x2F;sources&#x2F;includes -I&#x2F;usr&#x2F;local&#x2F;cuda-$(CUDA_VER)&#x2F;includeifeq ($(OPENCV), 1)COMMON&#x3D; -DOPENCVCFLAGS+&#x3D; $(shell pkg-config --cflags opencv4 2&gt; &#x2F;dev&#x2F;null || pkg-config --cflags opencv)LIBS+&#x3D; $(shell pkg-config --libs opencv4 2&gt; &#x2F;dev&#x2F;null || pkg-config --libs opencv)endifCUFLAGS:&#x3D; -I&#x2F;opt&#x2F;nvidia&#x2F;deepstream&#x2F;deepstream&#x2F;sources&#x2F;includes -I&#x2F;usr&#x2F;local&#x2F;cuda-$(CUDA_VER)&#x2F;includeLIBS+&#x3D; -lnvinfer_plugin -lnvinfer -lnvparsers -L&#x2F;usr&#x2F;local&#x2F;cuda-$(CUDA_VER)&#x2F;lib64 -lcudart -lcublas -lstdc++fsLFLAGS:&#x3D; -shared -Wl,--start-group $(LIBS) -Wl,--end-groupINCS:&#x3D; $(wildcard *.h)SRCFILES:&#x3D; $(filter-out calibrator.cpp, $(wildcard *.cpp))ifeq ($(OPENCV), 1)SRCFILES+&#x3D; calibrator.cppendifSRCFILES+&#x3D; $(wildcard layers&#x2F;*.cpp)SRCFILES+&#x3D; $(wildcard *.cu)TARGET_LIB:&#x3D; libnvdsinfer_custom_impl_Yolo.soTARGET_OBJS:&#x3D; $(SRCFILES:.cpp&#x3D;.o)TARGET_OBJS:&#x3D; $(TARGET_OBJS:.cu&#x3D;.o)all: $(TARGET_LIB)%.o: %.cpp $(INCS) Makefile$(CC) -c $(COMMON) -o $@ $(CFLAGS) $&lt;%.o: %.cu $(INCS) Makefile$(NVCC) -c -o $@ --compiler-options &#39;-fPIC&#39; $(CUFLAGS) $&lt;$(TARGET_LIB) : $(TARGET_OBJS)$(CC) -o $@  $(TARGET_OBJS) $(LFLAGS)clean:rm -rf $(TARGET_LIB)rm -rf $(TARGET_OBJS)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述代码中，我们只需要知道几个函数便可以实现我们想要的功能</p><ul><li>CFLAGS+= -I/opt/nvidia/deepstream/deepstream/sources/includes -I/usr/local/cuda-$ 在这里表示定义一个名为CUFLAGS的变量，于指定编译CUDA源文件时要使用的选项。其中，-I选项用于指定要包含的头文件路径，/opt/nvidia/deepstream/deepstream/sources/includes和/usr/local/cuda-$(CUDA_VER)/include分别是两个包含的头文件路径。在Makefile中，变量用于存储值，可以在Makefile中的其他位置使用。如果我们想在待编译的cpp文件中引入&lt;serial/serial.h&gt;头文件，那么可以在其后加上这句:CFLAGS+= -I/opt/ros/melodic/include</li><li>LIBS+= -lnvinfer_plugin -lnvinfer -lnvparsers -L/usr/local/cuda-$(CUDA_VER)/lib64 -lcudart -lcublas -lstdc++fs 表示定义一个名为LIBS的变量，其中包含要链接的库文件列表，包括nvinfer_plugin、nvinfer、nvparsers、cudart、cublas和stdc++fs库文件。如果我们想链接库文件/opt/ros/melodic/lib/libserial.so，那么我们可以加上这句:LIBS+= -L/opt/ros/melodic/lib -lserial</li></ul><p>一般来说了解了这两句就基本可以解决大部分问题了</p><h3 id="2-3-LD-PRELOAD加载动态库">2.3 LD_PRELOAD加载动态库</h3><p>LD_PRELOAD是个环境变量，用于动态库的加载，动态库加载的优先级最高，一般情况下，其加载顺序为LD_PRELOAD &gt; LD_LIBRARY_PATH &gt; /etc/ld.so.cache &gt; /lib&gt;/usr/lib。程序中我们经常要调用一些外部库的函数，以open()和execve()为例，如果我们有个自定义这两函数，把它编译成动态库后，通过LD_PRELOAD加载，当程序中调用open函数时，调用的其实是我们自定义的函数。这个功能可以帮助我们实现在执行文件外部链接一些库文件。</p><h3 id="2-4-相关编译命令">2.4 相关编译命令</h3><p>一般来说，我们会在CMakeList.txt的同级路径下创建一个build文件夹（文件夹命名可随意），然后进入到build文件夹后，打开终端，然后输入命令：<code>cmake ..</code><br>之后待编译完成后，我们会发现在build文件夹下会出现Makefile文件，随后我们再在命令行中输入命令：<code>make</code><br>成功之后，便会生成我们想要的可执行文件了。<br>相对路径如下所示：<br>----CMakeList.txt   (<code>$ mkdir build</code>)<br>----build          (<code>$ cd build</code>)(<code>$ cmake ..</code>)<br>--------Makefile   (<code>$ make</code>)<br>--------相关可执行文件</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;问题背景&quot;&gt;问题背景&lt;/h2&gt;
&lt;p&gt;这个问题是我在做海赛C2比赛编写部署自动打靶算法遇到的。先简单叙述一下起因，由于我们C2队伍使用的是Jetson Nano来识别靶心，进而实现自动打靶功能，于是算法识别这方面就由我来进展。在网上参考了一些部署方案。最终选择了使</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>关于如何使用Hexo搭建自己的Github网站</title>
    <link href="https://sprli.github.io/2023/05/18/build_web/"/>
    <id>https://sprli.github.io/2023/05/18/build_web/</id>
    <published>2023-05-18T15:52:40.130Z</published>
    <updated>2023-05-19T03:12:54.918Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、下载Git与Nodejs">一、下载Git与Nodejs</h2><p>这里可以自行参考网上教程下载</p><h2 id="二、使用hexo创建个人博客">二、使用hexo创建个人博客</h2><h3 id="2-1-创建Blog根目录">2.1 创建Blog根目录</h3><ol><li>在本地创建一个文件夹，此文件夹将用来管理你的个人博客网站，如下图，我再F盘创建了一个git_blog文件夹<br><img src="/images/build_hexo/image1.png" alt="image1"></li><li>然后打开Git bash并输入<code>cd F:/git/blog</code>，如下图<br><img src="/images/build_hexo/image2.png" alt="image2"></li><li>然后再输入命令</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-cli <span class="token parameter variable">-g</span>hexo init<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>其中hexo init命令可能会失败，可以多试几次，最好挂梯子运行<br>全部输入完后，可以发现当前文件夹下多出一些文件夹和相关配置文件。<br><img src="/images/build_hexo/image4.png" alt="image4"></p><ul><li>关于这些文件夹，可以先做一个简单的介绍：<ul><li>node_modules: 依赖包</li><li>public：存放生成的页面</li><li>scaffolds：生成文章的一些模板</li><li>source：用来存放你的文章</li><li>themes：主题</li></ul></li></ul><ol start="4"><li>然后输入命令：</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span>hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>完成后会显示如下内容<br><img src="/images/build_hexo/image5.png" alt="image5"><br>在浏览器中输入<a href="http://localhost:4000/">http://localhost:4000/</a>后可以进入Hexo传统页面，如下<br><img src="/images/build_hexo/image3.png" alt="image3"></p><h3 id="2-2-Github创建仓库">2.2 Github创建仓库</h3><ol><li>首先需要一个Github账号，关于创建Github账号，这里就略去了</li><li>创建一个Github仓库，需要注意的是，仓库的名称必须为你的Github用户名，如下：因为我的用户名为Sprli，<a href="http://xn--Sprli-dq1hu9a34zzzxxjp8t7c.github.io">故仓库名称为Sprli.github.io</a><br><img src="/images/build_hexo/image6.png" alt="image6"></li><li>创建完后回到Git Bash窗口，输入以下命令：</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> config <span class="token parameter variable">--global</span> user.name <span class="token string">"your name"</span> <span class="token comment"># 注意这里是你的Github用户名</span><span class="token function">git</span> config <span class="token parameter variable">--global</span> user.email <span class="token string">"your email"</span> <span class="token comment"># 注意这里是你的Github邮箱</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如下： 这里Sprli为我的Github用户名，9****.qq.com为我的邮箱<br><img src="/images/build_hexo/image7.png" alt="image7"></p><h3 id="2-3-创建ssh，便于链接Github">2.3 创建ssh，便于链接Github</h3><ol><li>创建ssh， 输入命令后一直回车即可<br><code>ssh-keygen -t rsa -C &quot;your email</code><br>之后会提示你已经完成ssh的创建，在文件夹中找到.ssh这个隐藏文件夹，其中Spring为我电脑本地户名<br><img src="/images/build_hexo/image8.png" alt="image8"><br>进入该文件夹后，可以发现文件夹下有如下文件：<br><img src="/images/build_hexo/image9.png" alt="image9"><br>记住上图圈红文件，在Github的setting中找到SSH keys，将id_rsa.pub中的内容全部复制到key中去，title内容随便填写就行<br><img src="/images/build_hexo/image10.png" alt="image10"><br><img src="/images/build_hexo/image12.png" alt="image12"><br><img src="/images/build_hexo/image13.png" alt="image13"><br>操作完成后，恭喜你，快成功了！！！</li></ol><h3 id="2-4-将hexo部署到Github">2.4 将hexo部署到Github</h3><p>在git_blog文件夹下找到_config.yml文件，这是属于你的博客的配置文件，可以在这里面直接修改 姓名，内容等用户的信息。（可以使用vscode或者记事本等编辑器都可以）</p><h4 id="2-4-1-修改其中的必要信息">2.4.1 修改其中的必要信息</h4><ol><li>修改其中的url为<code>https://username.github.io</code>，其中username为你Github用户名<br><img src="/images/build_hexo/image14.png" alt="image14"></li><li>将deploy部分修改为：</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Deployment</span><span class="token comment">## Docs: https://hexo.io/docs/one-command-deployment</span><span class="token comment"># deploy:</span><span class="token comment">#   type: ''</span>deploy:  type: <span class="token function">git</span>  repo: https://github.com/username/username.github.io.git  <span class="token comment"># 其中的username替换为你的Github用户名</span>  branch: ph-pages  <span class="token comment"># 注意branch不能为master，不然可能会出错</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/build_hexo/image15.png" alt="image15"><br>3. 安装git部署命令工具<br><code>npm install hexo-deployer-git --save</code><br>随后输入以下命令无错误后即完成在Github上的部署</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo cleanhexo ghexo d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>其中<code>hexo clean</code>清除了你之前生成的东西，也可以不加。<code>hexo generate</code>生成静态文章，可以用<code>hexo g</code>缩写，<code>hexo deploy</code>部署文章，可以用<code>hexo d</code>缩写。如果是在离线端即 localhost:4000端测试你的博客，则只需要<code>hexo g</code> + <code>hexo s</code>即可，无需<code>hexo d</code>，其中<code>hexo s</code>是<code>hexo server</code>的缩写。</p><h3 id="2-5-发布自己的博客">2.5 发布自己的博客</h3><p>在git_blog文件夹下找到source/_posts文件夹，在其中创建.md格式文件，然后在其中编写完自己的博客后，使用<code>hexo clean</code> + <code>hexo g</code> + <code>hexo d</code>即完成自己博客的编写与上传。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、下载Git与Nodejs&quot;&gt;一、下载Git与Nodejs&lt;/h2&gt;
&lt;p&gt;这里可以自行参考网上教程下载&lt;/p&gt;
&lt;h2 id=&quot;二、使用hexo创建个人博客&quot;&gt;二、使用hexo创建个人博客&lt;/h2&gt;
&lt;h3 id=&quot;2-1-创建Blog根目录&quot;&gt;2.1 创建B</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>关于Jetson Xavier NX 板子的系统烧录</title>
    <link href="https://sprli.github.io/2023/05/18/Jetson%20NX/"/>
    <id>https://sprli.github.io/2023/05/18/Jetson%20NX/</id>
    <published>2023-05-18T08:07:49.654Z</published>
    <updated>2023-07-29T20:10:41.504Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、准备">一、准备</h2><ol><li>Ubuntu电脑 or 虚拟机（Ubuntu系统）</li><li>能够进行数据传输的Micro-USB数据线</li><li>显示屏 、HDMI转接线、键鼠</li></ol><h2 id="二、进行烧录（参考瑞泰教程）">二、进行烧录（参考瑞泰教程）</h2><h3 id="2-1-系统软件包的下载">2.1 系统软件包的下载</h3><p>2.1.1 烧录所需文件集中在这两个文件夹中，在本部分我选择安装LT4 R32.7.1版本</p><img src="/images/Jetson/image-20230311205757974.png" alt="image-20230311205757974" style="zoom:50%;" /><p>2.1.2根据Jetson类型进行选择</p><img src="/images/Jetson/image-20230311205921697.png" alt="image-20230311205921697" style="zoom:50%;" /><p>2.1.3根据载板型号进行选择</p><img src="/images/Jetson/image-20230311210038630.png" alt="image-20230311210038630" style="zoom:50%;" /><p>2.1.4随便选择一个版本</p><img src="/images/Jetson/image-20230311210058553.png" alt="image-20230311210058553" style="zoom:50%;" /><p>2.1.5下载对应文件，其中rtso-6002对应位置即为载板型号</p><img src="/images/Jetson/image-20230311210118374.png" alt="image-20230311210118374" style="zoom:50%;" /><p>2.1.6选择对应版本的L4T文件</p><img src="/images/Jetson/image-20230311210156444.png" alt="image-20230311210156444" style="zoom:50%;" /><p>2.1.7下载相应文件</p><img src="/images/Jetson/image-20230311210216935.png" alt="image-20230311210216935" style="zoom:50%;" /><h3 id="2-2-在PC端Ubuntu系统进行烧录环境准备">2.2 在PC端Ubuntu系统进行烧录环境准备</h3><p>2.2.1 将上述文件拷贝至烧录主机同一目录下</p><p>2.2.2 解压 Linux Driver Package</p><p><code>$ tar -vxf Jetson_Linux_R32.7.1_aarch64.tbz2</code></p><p>2.2.3 设置根文件系统</p><ol><li><p>进入Linux Driver Package 的根文件系统目录</p><p><code>$ cd &lt;your_L4T_root&gt;/Linux_for_Tegra/roofs</code></p></li><li><p>解压 the Root File System ：</p><p><code>$ sudo tar -jxpf ../../Tegra_Linux_Sample-Root-Filesystem_R32.7.1_aarch64.tbz2</code></p></li></ol><p>2.2.4 安装 BSP 支持包</p><ol><li><p>将 Realtimes-L4T-<version>.tar 包解压到与 Linux_for_Tegra 文件夹同级目录下面，使用命令：</p><p><code>$ tar -xvf Realtimes-L4T-&lt;version&gt;.tar</code></p></li><li><p>进入到 Realtimes-L4T 文件夹，运行：</p><p><code>$ sudo ./install.sh</code><br>安装成功会有 success 提示！</p></li><li><p>运行 apply_binaries.sh 脚本拷贝 NVIDIA 用户空间库进入目标文件系统<br><code>$ cd ../Linux_for_Tegra/</code><br><code>$ sudo ./apply_binaries.sh</code></p></li></ol><h3 id="3-1-系统烧录">3.1 系统烧录</h3><p>3.3.1先c将板子进入recovery模式，然后将板子与主机通过Micro-USB数据线连接，在PC端的Linux_for_Tegra目录下进行如下操作：<br><code>$ sudo ./flash.sh realtimes/rtso-&lt;model&gt; mmcblk0p1</code><br>注意：rtso-<model>指的是板子型号，例如我使用的板子是rtso-6002E-v1.2，则命令为：<br><code>$ sudo ./flash.sh rtso-6002e-1.2v mmcblk0p1</code></p><p>3.3.2 可能遇到的问题</p><ol><li><p>板子型号查看，一般来说板子上会带有型号，若找不到可以咨询卖方</p><img src="/images/Jetson/image-20230311213021400.png" alt="image-20230311213021400" style="zoom:50%;" /></li><li><p>关于输入选项，如下，可以发现红框圈中的有很多型号的选项，其中rtso-6002e表示rtso-6002-emmc板，rtso-6002则是另一种类型的板子，并且6002-emmc下还有v1.2、v1.3等型号，根据板子进行选择。（一定不要弄错，这些文件是与主板相配的）</p></li></ol><p><img src="/images/Jetson/image-20230311214628664.png" alt="image-20230311214628664"></p><p>3.3.3 报错一</p><p><img src="/images/Jetson/image-20230311214653624.png" alt="image-20230311214653624"></p><p>如上报错需考虑两个原因：</p><ol><li>主机与板子进行数据传输的Micro-USB数据线是否具有传输数据的作用，可以使用lsusb查看是否含有Nvidia Crop；</li><li>板子是否进入了recovery模式。</li></ol><p>3.3.4 报错二</p><p><img src="/images/Jetson/image-20230319005550878.png" alt="image-20230319005550878"></p><p>仔细观察可以发现问题在于一个<code>.py</code>文件执行错误，可以使用命令<code>$ sudo apt install python2.7 python3 python</code>安装python，然后重新烧录解决。</p><h3 id="3-4-配置板子系统">3.4 配置板子系统</h3><p>由于瑞泰板子是上电自启动的，将板子和显示屏以及键鼠连接，进入类似Ubuntu系统开机配置界面，除了地区选择上海外，其余保持默认即可。能够正常开机，则表明烧录成功。随后可以发现，其图形化界面和Ubuntu几乎没有什么区别。</p><h2 id="三、进行系统迁移（视情况选择）">三、进行系统迁移（视情况选择）</h2><h3 id="3-1-方法一">3.1 方法一</h3><p>3.1.1 查看SSD设备名称<br>系统启动前，将SSD插入到板子的内存接口处（由于瑞泰板子自身装有一个120GB的内存卡，因此可以直接使用其自身的SSD卡即可）。系统启动后，使用<code>$ sudo fdisk -l</code>命令查看SSD设备名称，例如：nvme0n1、mmcblk1，本文使用mmcblk1为例。<br>3.1.2 对SSD进行格式化<br>如果SSD之前没有进行格式化，需要把SSD格式化后再使用。对于已挂载的SSD卡，需要使用umount卸载SSD卡，再格式化。卸载命令：<code>sudo umount /dev/mmcblk1</code>；格式化命令：<code>$ sudo mkfs.ext4 /dev/mmcblk1</code><br>3.1.3 创建一个新的GPT分区<br><code>$ sudo parted /dev/mmcblk1 mklabel gpt</code><br>3.1.4 添加分区<br><code>$ sudo parted /dev/mmcblk1 mkpart primary 0GB &lt;Size&gt;</code><br>Size是分区的大小，最小8GB，建议可以将SSD卡内存全部添入<br>例如：准备分区的大小是50GB，则命令是：<br><code>$ sudo parted /dev/mmcblk1 mkpart primary 0GB 50GB</code><br>添加完分区后，使用<code>$ sudo fdisk -l</code>可以看到mmcblk1下新增一个分区，名为：mmcblk1p1</p><p>3.1.5 格式化分区<br><code>$ sudo mkfs.ext4 /dev/mmcblk1p1</code><br>把分区格式化为ext4 格式<br>3.1.6 拷贝roofs到SSD<br><code>$ sudo dd if=/dev/mmcblk0p1 of=/dev/mmcblk1p1 bs=1M</code><br>其中mmcblk0p1是系统原先所在位置，mmcblk1p1则是我们的转移目标区域<br>3.1.7 修复分区<br><code>$ sudo -s</code><br><code>$ fsck.ext4 /dev/mmcblk1p1</code><br>若遇到输入yes or no，请全部输入yes</p><p>3.1.8 调整系统分区大小<br><code>$ sudo resize2fs /dev/mmcblk1p1</code></p><p>3.1.9 烧写从SD卡启动系统<br><code>$ sudo ./flash.sh realtimes/rtso-&lt;model&gt; mmcblk1p1</code><br>这一步骤和烧录步骤一摸一样，需要注意的是目录位置、烧录系统文件与最开始烧录时是一样的，且目标位置名称变化了<br>重新烧录完后，进入系统后，输入<code>$ df -h</code>可以看到mmcblk1p1成为根目录，系统已从SD卡启动。</p><h3 id="3-2-方法二">3.2 方法二</h3><p>[^参考博客]: <a href="http://t.csdn.cn/Ne0Bk">http://t.csdn.cn/Ne0Bk</a>  <a href="http://t.csdn.cn/ZrDlI">http://t.csdn.cn/ZrDlI</a></p><p>3.2.1 将SD卡进行格式化操作并挂载到系统下，操作如下：<br>系统迁移的前提是将SD卡挂载到系统下，先需要使用如下命令将SD卡格式化为EXT4格式：<br><code>$ sudo mke2fs -t ext4 /dev/mmcblk1p1</code><br>然后将SD卡挂载到/mnt下：<br><code>$ sudo mount /dev/mmcblk1p1 /mnt</code></p><p>3.2.2 克隆所需文件：</p><p><code>$ git clone https://github.com/jetsonhacks/rootOnNVMe.git</code></p><p>3.2.3 进入下载的文件夹中，<a href="http://xn--copy-rootfs-ssd-gm6x791zrggm36j4oi1j3f.sh">编辑脚本文件copy-rootfs-ssd.sh</a>，然后运行该脚本，将系统复制到SSD中。<br><code>cd ./rootOnNVMe</code><br><code>sudo gedit ./copy-rootfs-ssd.sh</code><br>将文件中的<code>/dev/nvme0n1p1 </code>修改为<code>/dev/mmcblk1</code><br><code>sudo ./copy-rootfs-ssd.sh</code></p><img src="/images/Jetson/image-20230311225106076.png" alt="image-20230311225106076" style="zoom: 80%;" /><p>3.2.4 进入到<code>rootOnNVMe/data</code>目录下，修改其中的脚本文件:<code>setssdroot.sh</code>与<code>setssdroot.service</code>，将其中的<code>/dev/nvme0n1p1</code>修改为<code>/dev/mmcblk1</code>，方法同上。</p><p><img src="/images/Jetson/image-20230311225229373.png" alt="image-20230311225229373"></p><p>3.2.5 回到rootOnNVMe目录下，执行以下命令：<br><code>sudo ./setup-service.sh</code></p><p>成功后如下图：</p><img src="/images/Jetson/image-20230311225311334.png" alt="image-20230311225311334" style="zoom:50%;" /><p>3.2.6 重新启动jetson板后，使用命令<code>$ df -h</code>查看，可以发现系统已经完成迁移</p><h2 id="四、安装Jepack">四、安装Jepack</h2><h3 id="4-1、基本步骤">4.1、基本步骤</h3><p>4.1.1 安装前信息确认以及更新软件源（在板子上进行）<br>给Xavier NX安装软件之前需先确定jetson设备系统l4t版本，因为NVDIA jetpack跟该版本号具有一定的对应关系，如果版本号不对应会导致出现一些异常。具体的对应关系可以参考Jetpack的说明：</p><p>在Xavier NX设备上使用以下命令可以查看系统的L4T版本号：<br><code>$ head–n 1 /etc/nv_tegra_release</code></p><p>4.1.2 进入载板系统，打开SysteamSettings–&gt;Software&amp;Updates&gt;Ubuntu Software</p><p>4.1.3 下载安装Jetpack/sdkmanager并运行（在PC端Ubuntu系统上进行）<br>[sdkmanager下载网址]: <a href="https://developer.nvidia.com/drive/sdk-manager">https://developer.nvidia.com/drive/sdk-manager</a></p><p>选择安装最新版本的sdkmanager下载安装<br>安装命令：<code>$ sudo dpkg -i sdkmage&lt;……&gt;.deb</code> or <code>$ sudo apt install ./sdkmanger-&lt;……&gt;.deb</code><br>运行命令：<code>$ sdkmanager</code></p><p>运行界面和操作如下：</p><ol><li><p>登录界面（低版本可能无法登录）</p><img src="/images/Jetson/image-20230311232026679.png" alt="image-20230311232026679" style="zoom:50%;" /></li><li><p>点击圈中的1、2，进行选择Jetson类型以及与LT4相对应的Jetpack版本，3取消勾选。如果2中未发现与其对应的Jetpack版本，则运行sdkmanager的命令改为：<code>$ sdkmanager --archivedversions</code>，其它操作不变。</p><img src="/images/Jetson/image-20230311232300525.png" alt="image-20230311232300525" style="zoom:50%;" /></li><li><p>由于以及安装过系统，圈中的1取消勾选，圈中的2可以选择合适的位置（默认不变），圈中的3注意取消勾选<strong>Download now.Install later.<strong>点击</strong>continue</strong>。</p><img src="/images/Jetson/image-20230311233159191.png" alt="image-20230311232542687" style="zoom:50%;" /></li><li><p>输入PC端Ubuntu主机密码</p><img src="/images/Jetson/image-20230311232559144.png" alt="image-20230311232559144" style="zoom:50%;" /></li><li><p>圈中的1，实际上应是显示有设备连接的；圈中的2填写<strong>板子Ubuntu系统</strong>的Username和Password；随后点击Install。</p><img src="/images/Jetson/image-20230311233500272.png" alt="image-20230311233500272" style="zoom:50%;" /></li><li><p>接着进入以下界面，这些指标都是板子的指标，如内存是否足够、网络是否连接等。</p><p><img src="/images/Jetson/image-20230311234633908.png" alt="image-20230311234633908"></p><p>7.最后出现接下来画面即成功</p><p><img src="/images/Jetson/image-20230319113455316.png" alt="image-20230319113455316"></p></li></ol><h3 id="4-2-问题及解决">4.2 问题及解决</h3><p>4.2.1 如上图，如果出现Internet connection问题，按照其指示可以采取如下方法解决：</p><ol><li>在jetson板上终端输入：<code>$ ping -c 3 www.nvidia.com</code></li></ol><p><img src="/images/Jetson/image-20230311234239264.png" alt="image-20230311234239264"></p><ol start="2"><li><p>将出现的Ip地址放到jetson板子的/etc/hosts文件中</p></li><li><p>使用命令：<code>$ sudo gedit /etc/hosts</code></p></li></ol><p>​       在文件中添加一行：<code>23.48.214.59 nvidia.com</code></p><ol start="4"><li>保存后点击Retry即可。</li></ol><p>如果上述方法行不通，则可能是sdkmanager<strong>版本不是最新</strong>造成的。</p><p>4.2.2 若出现第三个Accept to APT……错误，则可能是jetson板上的源未更新造成的。</p><ol><li>可以在jetson板上依次输入命令：</li></ol><p><code>$ sudo apt-get update</code> &amp;<code>$ sudo apt-get upgrade</code></p><ol start="2"><li><p>更新完后Retry即可。</p></li><li><p>有时光多Retry几次可能就会成功。</p></li></ol><p>若上述操作失效，则可以替换Jetson板上的Ubuntu源（注意是<strong>Jetson源</strong>），重新更新尝试一下；或者退出sdkmanager重新弄一遍。</p><h2 id="五、安装系统所需的包">五、安装系统所需的包</h2><h3 id="5-1-配置cuda环境变量">5.1 配置cuda环境变量</h3><p><code>vi ~/.bashrc  # 打开/.bashrc文件</code><br>将以下内容输入该文件中（末尾即可）</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span>/usr/local/cuda10.2/bin:<span class="token environment constant">$PATH</span> <span class="token comment"># cuda后跟的是cuda版本</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span>/usr/local/cuda10.2/lib64:<span class="token variable">$LD_LIBRARY_PATH</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_ROOT</span><span class="token operator">=</span>/usr/local/cuda10.2  <span class="token comment"># 这一项不是很确定是否有用</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="5-2-配置系统级安装包">5.2 配置系统级安装包</h3><p>输入以下命令即可</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> build-essential <span class="token function">make</span> cmake cmake-curses-gui<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token function">git</span> g++ pkg-config <span class="token function">curl</span>  <span class="token function">zip</span> zlib1g-dev libopenblas-base libopenmpi-dev <span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libatlas-base-dev gfortran libcanberra-gtk-module libcanberra-gtk3-module<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libhdf5-serial-dev hdf5-tools libhdf5-dev<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token function">nano</span> <span class="token function">locate</span> <span class="token function">screen</span><span class="token comment">#scipy 依赖和 cython</span><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libfreetype6-dev <span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> protobuf-compiler libprotobuf-dev openssl<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libssl-dev libcurl4-openssl-dev<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> cython3<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libxml2-dev libxslt1-dev<span class="token comment">#opencv 依赖</span><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libavcodec-dev libavformat-dev libswscale-dev<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libxvidcore-dev libavresample-dev<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libtiff-dev libjpeg-dev libpng-dev<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-3-安装配置Python">5.3 安装配置Python</h3><p>5.3.1 默认安装python3.6版本</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> python3-dev python3-testresources python3-setuptools<span class="token function">wget</span> https://bootstrap.pypa.io/pip/3.6/get-pip.py<span class="token function">sudo</span> python3 get-pip.py <span class="token comment"># 该命令可能会失败，显示python3使用的python3.6版本较低，导致不成功，只要下载对应版本的pip就行，使用以下命令进行替换：wget https://bootstrap.pypa.io/pip/3.6/get-pip.py</span><span class="token function">rm</span> get-pip.py <span class="token comment"># 然后换pip源</span><span class="token function">mkdir</span> ~/.pip<span class="token function">vim</span> ~/.pip/pip.conf <span class="token comment"># 换清华源</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>粘贴以下内容到该文件<br><code>[global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple</code></p><p>5.3.2 解决sudo python3 get-pip.py失败，这里我选择使用python3.7版本</p><ol><li>安装python3.7</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> update  <span class="token comment"># 更新(可跳过)</span><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> python3.7python3.7 <span class="token parameter variable">-V</span>  <span class="token comment">#查看是否安装成功</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="2"><li>创建软连接，使python3默认指向python3.7</li></ol><ul><li>首先把之前的软连接删除：</li></ul><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">rm</span> <span class="token parameter variable">-rf</span> /usr/bin/python3 <span class="token function">which</span> python3.7  <span class="token comment"># 查看python3.7 安装路径.这里输出/usr/bin/python3.7</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>创建新的软连接：</li></ul><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">ln</span> <span class="token parameter variable">-s</span> /usr/bin/python3.7 /usr/bin/python3  <span class="token comment"># 添加python3的软链接。 /usr/bin/python3.7 即 which python3.7输出的安装路径</span>python3 <span class="token parameter variable">-V</span>  <span class="token comment"># 测试是否安装成功</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="3"><li>切换python版本，<br><a href="jetson%E5%8F%AF%E4%BB%A5%E5%AE%89%E8%A3%85minconda%E6%9D%A5%E4%BD%BF%E7%94%A8conda%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%EF%BC%8C%E4%BD%86%E6%98%AF%E4%B8%8D%E5%A6%82%E5%AE%89%E8%A3%85virtualenv%E6%9D%A5%E7%9A%84%E6%96%B9%E4%BE%BF%EF%BC%8C%E5%B9%B6%E4%B8%94%E5%8D%A0%E5%86%85%E5%AD%98%E4%B9%9F%E4%B8%8D%E5%B0%8F">^解释</a>: 对于不同版本的jetpack，其cuda对应的python版本有所不同，使用该方法便于配合cuda的使用</li></ol><ul><li>首先查看python文件<br><code>ls /usr/bin/python* # 查看python文件，会出现python2.7、python3.6、python3.7三个版本</code></li><li>首先看看系统是否配置过python相关的管理信息<br><code>update-alternatives --list python # 如果显示：no alternatives for python，表示没有配置过。</code></li><li>使用以下命令进行配置：</li></ul><pre name="code" class="python">sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.6 2sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.7 3</pre><ul><li>配置成功，会提示你<code> in auto mode</code>.这个时候我们再次查看配置<br><code>update-alternatives --list python</code></li><li>会看到我们的三个版本已经成功进行了配置。如果需要切换版本，输入命令<br><code>sudo update-alternatives --config python #  然后输入相应的版本序号即可</code></li><li>最后使用：<code>python --version</code>查看版本号，可以发现配置成功</li></ul><h3 id="5-4-安装jtop管理GPU">5.4 安装jtop管理GPU</h3><p>输入命令安装jtop：<br><code>sudo -H pip install jetson-stats</code><br>安装成功后，输入<code>sudo jtop</code>即可查看硬件相关信息</p><h3 id="5-5-安装virtualenv来创建虚拟环境">5.5 安装virtualenv来创建虚拟环境</h3><ol><li>安装与配置</li></ol><ul><li>使用pip下载virtualenv</li></ul><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> pip <span class="token function">install</span> virtualenv virtualenvwrapper<span class="token function">vim</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>将以下内容输入其中：</li></ul><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#virtualenv and virtualenvwrapper</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">WORKON_HOME</span><span class="token operator">=</span><span class="token environment constant">$HOME</span>/.virtualenvs <span class="token comment">#指定所有的需拟环境的安装位置</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">VIRTUALENVWRAPPER_PYTHON</span><span class="token operator">=</span>/usr/bin/python3.6 <span class="token comment">#指定解释器，改为cuda对应的python版本</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>终端输入指令激活virtualenv</li></ul><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">mkdir</span> <span class="token environment constant">$HOME</span>/.virtualenvs<span class="token builtin class-name">source</span> /usr/local/bin/virtualenvwrapper.sh <span class="token comment">#进行激活生效</span><span class="token builtin class-name">source</span> ~/.bashrc <span class="token comment">#重新载入</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="2"><li>virtualenv的使用相关操作</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">mkvirtualenv name <span class="token comment"># 创建一个环境</span>mkvirtualenv <span class="token parameter variable">-p</span> /python目录/python.exe name <span class="token comment"># 不使用默认python版本、使用指定python版本创建环境</span>workon name <span class="token comment"># 激活环境</span>deactivate <span class="token comment"># 退出</span>rmvirtualenv name <span class="token comment"># 删除</span>lsvirtualenv <span class="token comment"># 所有环境</span>cpvirtualenv source_name dest_name <span class="token comment"># 复制虚拟环境</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="六、安装pytorch以及torchvision">六、安装pytorch以及torchvision</h2><h3 id="6-1-基本操作">6.1 基本操作</h3><ol><li>创建虚拟环境<br>[^声明]: 以创建虚拟环境名位torchli，安装1.10.0版本的pytorch和对应版本0.11.1的torchvision为例</li></ol><ul><li>使用以下命令创建虚拟环境</li></ul><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">Mkvirtualenv <span class="token parameter variable">-p</span> /usr/bin/python3.6 torchli <span class="token comment"># -p 后面跟着的是制定python的版本，因为有的pytorch对python版本有要求，所以要指定版本</span>workon torchli <span class="token comment"># 进入虚拟环境</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>如果遇见<code>workon command not find</code>，则使用以下命令<br><code>Source virtualenvwrapper.sh</code></li><li>然后再<code>workon torchli</code></li></ul><ol start="2"><li>安装pytorch</li></ol><ul><li>首先下载pytorch pip wheels（对应自己装的Jatpack的版本）<br>[下载网址]:<a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson/72048">https://forums.developer.nvidia.com/t/pytorch-for-jetson/72048</a></li><li>下载完后，输入命令：</li></ul><pre name="code" class="python">pip install torch-1.10.0-cp36-cp36m-linux_aarch64.whl # 安装pytorchgit clone --branch v0.11.1 https://github.com/pytorch/vision torchvision # 下载0.11.1版本cd torchvisionexport BUILD_VERSION=0.11.1python setup.py install --user # --user可加可不加</pre><ol start="3"><li>验证是否安装成功</li></ol><ul><li>上述操作完成后，输入命令：</li></ul><pre name="code" class="python">python # 进入python：import torch # 导入torch库torch.cuda.is_available()  # 验证cuda是否能使用，输出应为True，则pytorch安装成功import torchvision # 导入torchvision库print(Torchvision.__version__) # 打印版本号，未报错即成功</pre><h3 id="6-2-问题及解决">6.2 问题及解决</h3><p>6.2.1. 激活环境失败，报错输出：<code>workon command not find</code><br>输入命令<code>source virtualenvwrapper.sh # 输入之后再尝试激活即可</code><br>6.2.2. import torch时报错,Illegal instruction (core dumped)</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 修改环境变量</span><span class="token function">sudo</span> gedit /etc/profile <span class="token builtin class-name">export</span> <span class="token assign-left variable">OPENBLAS_CORETYPE</span><span class="token operator">=</span>ARMV8 <span class="token comment"># 将其加入最后面一行，然后保存</span><span class="token comment"># 更新环境变量</span><span class="token builtin class-name">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>6.2.3. import torchvision报错<br>[该报错大致可以分为两个问题]: 1、pillow和torchvision版本不对应出错；2、当前路径含有同名文件导致报错</p><ol><li>在import torchvision过程中遇到有关PIL库的提示报错<br>解决方法：尝试卸载当前的pillow，安装较低版本的pillow<br>输入命令：<pre name="code" class="python">pip uninstall pillowpip install pillow==6.1 # 一般来说安装此版本即可解决问题</pre></li><li>由于当前在torchvision文件夹下安装的torchvision，若不退出此路径也会导致import torchvision报错，报错提示路径问题<br>解决方法：退出当前文件夹路径，输入以下命令：<br><code>cd .. # 返回上级路径，然后再次尝试import torchvision</code></li></ol><h2 id="七、安装opencv">七、安装opencv</h2><h3 id="7-1-情形一">7.1 情形一</h3><p><a href="%E5%A6%82%E6%9E%9C%E5%9C%A8%E5%AE%89%E8%A3%85jetpack%E6%97%B6%E6%9C%AA%E5%AE%89%E8%A3%85opencv%EF%BC%8C%E6%88%96%E8%80%85%E6%98%AF%E6%83%B3%E6%8D%A2%E6%96%B0%E7%9A%84%E7%89%88%E6%9C%AC%EF%BC%8C%E5%A6%823.4.5%E3%80%82%E5%88%99%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%E4%BB%A5%E4%B8%8B%E6%96%B9%E6%B3%95%E5%AE%89%E8%A3%85opencv">^具体阐述</a>: 在新创建的python虚拟环境中，无法import cv2，且pip install opencv-python始终无法完成，故需要安装opencv，但是一般来说，安装jetpack后，自动安装的有opencv，若此opencv版本不影响你的代码，那么就可以进行以下操作便捷使用opencv库了</p><ol><li>首先在终端执行以下指令查找编译好的cv2库文件的路径</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">find</span> / <span class="token parameter variable">-iname</span> <span class="token string">"*cv2*"</span> <span class="token comment"># 得到类似路径/usr/lib/python3.6/dist-packages/cv2/python-3.6/cv2.cython-36m-aarch64-linux-gnu.so，重点是cv2.cython-36m-aarch64-linux-gnu.so文件要求一致</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>随后进入虚拟环境的site-packages文件夹下,并链接到查找到的cv2库文件路径即可</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> /home/nx407/.virtualenv/torchli/lib/python3.6/site-packages <span class="token comment"># 其中nx407是用户名、torchli是我建立的虚拟环境名</span><span class="token function">ln</span> <span class="token parameter variable">-s</span> /usr/lib/python3.6/dist-packages/cv2/python-3.6/cv2.cython-36m-aarch64-linux-gnu.so cv2.so  <span class="token comment"># 注意ln，link的意思，不是大写i</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="3"><li>安装完成后，在虚拟环境中执行下列指令以确保python能正确调用cv2。</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python">python               <span class="token operator">//</span>进入python<span class="token keyword">import</span> cv2cv2<span class="token punctuation">.</span>__version__    <span class="token operator">//</span>若安装成功且能正常调用，此处能输出安装的从v版本quit<span class="token punctuation">(</span><span class="token punctuation">)</span>               <span class="token operator">//</span>退出python<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="7-2-情形二">7.2 情形二</h3><ol><li><p>查看已预安装Opencv版本<br><code>pkg-config --modversion opencv</code></p></li><li><p>卸载原Opencv</p></li></ol><ul><li>如果是自己之前安装的话，就找到当初安装Opencv的build文件夹路径，然后进入该build目录执行卸载操作：</li></ul><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> <span class="token punctuation">..</span>./opencv-4.x.x/build<span class="token function">sudo</span> <span class="token function">make</span> uninstall<span class="token builtin class-name">cd</span> <span class="token punctuation">..</span>./opencv-4.x.x<span class="token function">sudo</span> <span class="token function">rm</span> <span class="token parameter variable">-r</span> build<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li>若不是则执行以下操作：</li></ul><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> purge libopencv*<span class="token function">sudo</span> <span class="token function">apt-get</span> purge python-numpy<span class="token function">sudo</span> <span class="token function">apt</span> autoremove // 删除其他未使用的apt包，可有可无<span class="token function">sudo</span> <span class="token function">apt-get</span> update<span class="token function">sudo</span> <span class="token function">apt-get</span> dist-upgrade<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li><p>下载Opencv3.4.5.zip文件</p></li><li><p>安装一些相关库和包</p></li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> installbuild-essential <span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> cmake <span class="token function">git</span> libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> --only-upgrade g++-5 cpp-5 gcc-5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>如果上述指令失败的话，可以尝试网上换源，如下<br>更新后再安装Qt5<br><code>sudo apt-get install qt5-default # qt5必须要安装成功，不过丢包概率不大，都能装上的</code></p><ol start="5"><li><p>CUDA部分源码的修改<br>先找到<code>cuda_gl_interop.h</code>文件，一般都是在<code>/usr/local/cuda/include</code>里<br>然后在命令框输入<br><code>sudo gedit /usr/local/cuda/include/cuda_gl_interop.h</code><br>这时会弹出一个文件如下图<br><img src="/images/Jetson/image-20230322013045837.png" alt="image-20230322013045837"><br>找到红框内代码，并按照图中代码更改为以上内容，然后点save保存，退出。</p></li><li><p>开始编译安装opencv-3.4.5<br>找到opencv-3.4.5所在文件夹（即前文解压后的文件夹），然后cd到build文件夹里面。<br>控制台输入：</p></li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">cmake <span class="token parameter variable">-D</span> <span class="token assign-left variable">CMAKE_BUILD_TYPE</span><span class="token operator">=</span>RELEASE <span class="token parameter variable">-D</span> <span class="token assign-left variable">CMAKE_INSTALL_PREFIX</span><span class="token operator">=</span>/usr/local <span class="token punctuation">\</span>      <span class="token parameter variable">-D</span> <span class="token assign-left variable">WITH_CUDA</span><span class="token operator">=</span>ON <span class="token parameter variable">-D</span> <span class="token assign-left variable">CUDA_ARCH_BIN</span><span class="token operator">=</span><span class="token string">"6.2"</span> <span class="token parameter variable">-D</span> <span class="token assign-left variable">CUDA_ARCH_PTX</span><span class="token operator">=</span><span class="token string">""</span> <span class="token punctuation">\</span>      <span class="token parameter variable">-D</span> <span class="token assign-left variable">WITH_CUBLAS</span><span class="token operator">=</span>ON <span class="token parameter variable">-D</span> <span class="token assign-left variable">ENABLE_FAST_MATH</span><span class="token operator">=</span>ON <span class="token parameter variable">-D</span> <span class="token assign-left variable">CUDA_FAST_MATH</span><span class="token operator">=</span>ON <span class="token punctuation">\</span>      <span class="token parameter variable">-D</span> <span class="token assign-left variable">ENABLE_NEON</span><span class="token operator">=</span>ON <span class="token parameter variable">-D</span> <span class="token assign-left variable">WITH_LIBV4L</span><span class="token operator">=</span>ON <span class="token parameter variable">-D</span> <span class="token assign-left variable">BUILD_TESTS</span><span class="token operator">=</span>OFF <span class="token punctuation">\</span>      <span class="token parameter variable">-D</span> <span class="token assign-left variable">BUILD_PERF_TESTS</span><span class="token operator">=</span>OFF <span class="token parameter variable">-D</span> <span class="token assign-left variable">BUILD_EXAMPLES</span><span class="token operator">=</span>OFF <span class="token punctuation">\</span>      <span class="token parameter variable">-D</span> <span class="token assign-left variable">WITH_QT</span><span class="token operator">=</span>ON <span class="token parameter variable">-D</span> <span class="token assign-left variable">WITH_OPENGL</span><span class="token operator">=</span>ON<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>接着输入：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">make</span><span class="token function">sudo</span> <span class="token function">make</span> <span class="token function">install</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="7"><li>配置opencv环境：<br><code>sudo gedit /etc/ld.so.conf.d/opencv.conf # 创建并打开该文件，输入以下内容</code><br><img src="/images/Jetson/image-20230322013134812.png" alt="image-20230322013134812"><br>执行下面的命令，使得刚才配置的路径生效<br><code>sudo ldconfig</code><br>然后打开bash.bashrc文件<br><code>sudo gedit /etc/bash.bashrc</code><br>在打开文件的最后加入如下命令</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">PKG_CONFIG_PATH</span><span class="token operator">=</span><span class="token variable">$PKG_CONFIG_PATH</span>:/usr/local/lib/pkgconfig<span class="token builtin class-name">export</span> PKG_CONFIG_PATH<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如图：<br><img src="/images/Jetson/img1.png" alt="img1"><br>然后保存文件，使其生效<br><code>source /etc/bash.bashrc</code><br>8. 检查是否成功安装opencv<br>可以先在jtop查看opencv的安装版本，正确安装后会显示：<br><img src="/images/Jetson/image-20230322013148567.png" alt="image-20230322013148567"><br>9. 之后连接一个摄像头，在终端输入，测试opencv是否能正常使用：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> /opencv-3.4.5/samples/cpp/example_cmakecmake <span class="token builtin class-name">.</span><span class="token function">make</span><span class="token comment"># 成功make后，执行</span>./opencv_example<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="10"><li>上述<code>./opencv_example</code>命令如果失败，原因可能是摄像头的索引错误，<br>输入<code>ls usb</code><br>查看摄像头，发现video1<br>换一个usb接口插入即可，再执行上述命令，可以发现摄像头成功打开。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、准备&quot;&gt;一、准备&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Ubuntu电脑 or 虚拟机（Ubuntu系统）&lt;/li&gt;
&lt;li&gt;能够进行数据传输的Micro-USB数据线&lt;/li&gt;
&lt;li&gt;显示屏 、HDMI转接线、键鼠&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;二、进行烧录</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>成功解决Pytorch模型转trt模型中得BatchNorm问题</title>
    <link href="https://sprli.github.io/2023/05/18/Torch2Trt/"/>
    <id>https://sprli.github.io/2023/05/18/Torch2Trt/</id>
    <published>2023-05-18T06:12:16.513Z</published>
    <updated>2023-05-18T12:37:42.911Z</updated>
    
    <content type="html"><![CDATA[<p>如果你想把你的模型投入到应用中或者是想提升模型的运行速度，除了对网络进行压缩、蒸馏外，最好的方法就是将模型转成tensor模型，使用tensorrt实现对网络的加速。但是当该模型的功能是图像增强或者是图像生成，并且模型中运用了大量的batchnorm2d函数，运用网上现成的方法会发现模型转成onnx以及trt后，模型的处理效果大幅下降，想解决此问题就可以详细往下看了：<br>我们的方法顺序是：pytorch模型先转成onnx模型，接着将onnx模型转成trt模型</p><h2 id="一、pytorch-to-onnx">一、pytorch to onnx</h2><h3 id="核心代码：">核心代码：</h3><pre name="code" class="python">import torchfrom torchvision.utils import save_imageimport osfrom nets.tiny_unet_2_channelxiangdeng_RCABup3_1_3 import Decoderimport argparseimport torch.nn as nnfrom torchvision import transforms as Tfrom torchvision.datasets import ImageFolderfrom torch.utils import dataimport onnximport onnxruntimeclass Loader(nn.Module):    def __init__(self, image_dir, batch_size=1, num_workers=4):        super(Loader, self).__init__()        self.image_dir = image_dir        self.batch_size = batch_size        self.num_workers = num_workers    def forward(self):        transform = list()        transform.append(T.Resize([704, 1280]))  # 注意要为256的倍数        transform.append(T.ToTensor())        transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))        transform = T.Compose(transform)        dataset = ImageFolder(self.image_dir, transform)        data_loader = data.DataLoader(dataset=dataset,                                      batch_size=self.batch_size,                                      num_workers=self.num_workers)        return data_loaderclass Solver(object):    def __init__(self, data_loader, config):        self.data_loader = data_loader        self.global_g_dim = config.global_G_ngf        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')        self.model_save_dir = config.model_save_dir        self.result_dir = config.result_dir        self.build_model()    def restore_model(self, resume_epoch):        """Restore the trained generator and discriminator."""        print('Loading the trained models from step {}...'.format(resume_epoch))        generator_path = os.path.join(self.model_save_dir, '{}-global_G.ckpt'.format(resume_epoch))        self.generator.load_state_dict(torch.load(generator_path, map_location=lambda storage, loc: storage))    def build_model(self):        """create a generator and a discrimin"""        self.generator = Decoder(self.global_g_dim)        self.generator.to(self.device)    def denorm(self, x):        out = (x + 1) / 2        return out.clamp_(0, 1)    def to_numpy(self, tensor):        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()    def test(self):        begin_epoch = 91        end_epoch = 92        step = 1        for k in range(begin_epoch, end_epoch, step):            self.restore_model(94)            self.generator.train()            modelData = "../model/demo" + str(k) + ".onnx"            # modelData = "demo_distok-1ok" + str(k) + ".onnx"            data_loader = self.data_loader            # with torch.no_grad():            for i, (val_img, _) in enumerate(data_loader):  # 出来的图片是RGB格式, 用PIL读取的                if i % 50 != 0:                    continue                x_real_name = data_loader.batch_sampler.sampler.data_source.imgs[i][0]                basename = os.path.basename(x_real_name)                result_path = os.path.join(self.result_dir, str(k))  # 生成的图片的保存文件夹                if not os.path.exists(result_path):                    os.makedirs(result_path)                result_path2 = os.path.join(result_path, basename)                distored_val = val_img.to(self.device)                clean_fake1 = self.generator(distored_val)                torch.cuda.synchronize()                clean_fake1 = clean_fake1.data.cpu()                save_image(self.denorm(clean_fake1), result_path2, nrow=1, padding=0)                torch.onnx.export(self.generator, distored_val, modelData, opset_version=9)                onnx_model = onnx.load(modelData)                onnx.checker.check_model(onnx_model)                ort_session = onnxruntime.InferenceSession(modelData,                                                            providers=['CUDAExecutionProvider'])                ort_inputs = {ort_session.get_inputs()[0].name: self.to_numpy(distored_val)}                ort_outs = ort_session.run(None, ort_inputs)                result_path1 = os.path.join(self.result_dir, "trt"+str(k))                result_pathtrt = os.path.join(result_path1, basename)                #save_image((self.denorm(torch.tensor(ort_outs[0]))),result_pathtrt, nrow=1, padding=0)                result = [val_img, torch.tensor(ort_outs[0]), clean_fake1]                result_concat1 = torch.cat(result, dim=3)                # break                save_image((self.denorm(result_concat1.data.cpu())), result_path2, nrow=2, padding=0)def main(config):    data_loader = Loader(config.data_dir)    solver = Solver(data_loader(), config)    solver.test()    #solver.build_model()    #solver.printnetwork()if __name__ == '__main__':    parser = argparse.ArgumentParser()    parser.add_argument('--global_G_ngf', type=int, default=16, help='number of conv filters in the first layer of G')    parser.add_argument('--num_workers', type=int, default=4)    parser.add_argument('--data_dir', type=str,                        default=r'D:\Data\Paired\underwater_imagenet\val')    parser.add_argument('--model_save_dir', type=str,                        #default='/home/ouc/Li/Torch2TRT/trt_outfile/model'                        default=r'C:\TensorRT-8.6.0.12\samples\python\zzzzFSpiral\modules')    parser.add_argument('--result_dir', type=str,                        default=r'C:\TensorRT-8.6.0.12\samples\python\zzzzFSpiral\result')    torch.cuda.set_device(0)    config = parser.parse_args()    main(config)</pre><p>当pytorch转成onnx时，需要将模型进行eval模式，因为在PyTorch中，模型训练和推理（inference）有两种模式：训练模式和评估模式（evaluation mode）。在训练模式下，模型会保留一些中间结果，以便进行反向传播和参数更新(如batchnorm2d在train和eval模型中的计算不一致，涉及到内部的变量running_mean和running_eval的计算（如下图所示）)。而在评估模式下，模型不会保留这些中间结果，以便进行推理。因此，在将PyTorch模型转换为ONNX模型时，需要将模型切换到评估模式，以确保模型的输出与推理结果一致。如果在转换模型之前不将模型切换到评估模式，可能会导致转换后的ONNX模型输出与预期不一致。因此，为了确保转换后的ONNX模型的正确性，需要将PyTorch模型切换到评估模式（eval mode）再进行转换。</p><pre name="code" class="python">class MyBatchNorm2d(nn.BatchNorm2d):    def __init__(self, num_features, eps=1e-5, momentum=0.1,                 affine=True, track_running_stats=True):        super(MyBatchNorm2d, self).__init__(            num_features, eps, momentum, affine, track_running_stats)    def forward(self, input):        self._check_input_dim(input)        exponential_average_factor = 0.0        if self.training and self.track_running_stats:            if self.num_batches_tracked is not None:                self.num_batches_tracked += 1                if self.momentum is None:  # use cumulative moving average                    exponential_average_factor = 1.0 / float(self.num_batches_tracked)                else:  # use exponential moving average                    exponential_average_factor = self.momentum        # calculate running estimates        if self.training:            mean = input.mean([0, 2, 3])            # use biased var in train            var = input.var([0, 2, 3], unbiased=False)            n = input.numel() / input.size(1)            with torch.no_grad():                self.running_mean = exponential_average_factor * mean\                    + (1 - exponential_average_factor) * self.running_mean                # update running_var with unbiased var                self.running_var = exponential_average_factor * var * n / (n - 1)\                    + (1 - exponential_average_factor) * self.running_var        else:            mean = self.running_mean            var = self.running_var        input = (input - mean[None, :, None, None]) / (torch.sqrt(var[None, :, None, None] + self.eps))        if self.affine:            input = input * self.weight[None, :, None, None] + self.bias[None, :, None, None]        return input</pre><p>当模型是train时，其<code>mean = input.mean([0, 2, 3])；var = input.var([0, 2, 3], unbiased=False)</code>，计算与当前的输入相挂钩，但是当模型是eval模式时，其<code>mean = self.running_mean；var = self.running_var</code>，计算与当前的输入无关，而是将学习到的running_mean与running_var直接作为当前计算的mean与var，由于该学习得到的均值与方差（running_mean与running_var）并不能完全适用所有的输入样例，因此模型在eval模式下的处理效果极大降低。</p><p>但是有人可能会想为什么模型转成onnx时要将模型设置为eval模式，直接设置为train模式不就可以解决处理效果下降的问题了吗？但是当你按该想法实验的时候，会发现虽然pytorch模型的处理效果没问题，但是onnx模型的处理效果还是一样的差，这又是为什么呢？我的猜测是onnx模型在推理时默认将batchnorm的模式设置为eval，进而输出的结果就存在问题了。这个是我个人的想法，大家有不同意见可以互相交流。</p><p>所以现在的问题就转换到了如何使模型在eval模式下计算的mean与var和当前输入相关，而不是依赖学习到的running_mean与running_eval。部分人可能遇到此问题就无从下手了，认为该问题是无法解决的。但是这个问题在我这里是能解决的。首先经过上述对问题的描述，大家对这个问题已经是比较清楚了。</p><p>接下来我将介绍两种很简单的方法来解决onnx模型处理效果差的问题：</p><h3 id="方法一：">方法一：</h3><h4 id="具体措施">具体措施:</h4><p>修改batchnorm2d中的源码，在if self.training：上方加一行self.training =True。这样尽管处于eval模式，但是batchnorm仍然是处于训练状态的，在这种情况下，mean与var自然就和input挂钩了。<br><img src="/images/Pytorch2trt/image-2.png" style="zoom: 200%;" /></p><h4 id="利弊：">利弊：</h4><p>不过这种方法虽然可以解决onnx模型处理效果差的问题，但是由该方法获得的onnx模型是无法成功转tensorrt的。原因是因为onnx模型的参数都是固定死的，正如上述我所展示的代码中，当模型处于训练模式时，running_mean与running_var是变化的，因此获得的onnx尽管输出没问题，但其内部是存在问题的。<br>batchnorm2d的源代码路径如下:<br><code>C:\Users\Spring\Anaconda3\envs\torchli\Lib\site-packages\torch\nn\modules\batchnorm.py</code></p><h3 id="方法二">方法二</h3><h4 id="具体措施-2">具体措施:</h4><p>修改batchnorm2d的源码，不过与方法一有所区别，具体修改见下图，之所以这样修改是因为batchnorm在eval模式下，mean与var和running_mean与running_val挂钩，故我们提前将学习到的running_mean与running_var设置成与input挂钩，然后就mean与var就和input联系起来了。<br><img src="/images/Pytorch2trt/image-20230514162311051.png" style="zoom: 200%;" /></p><h4 id="利弊：-2">利弊：</h4><p>不过这种方法虽然可以解决onnx模型处理效果差的问题，但是当可视化由该方法获得的onnx模型时，会发现batchnorm是不纯净的，上方多了一些计算分支（如右图所示），但是方法一的batchnorm是纯净的（如左图所示）。好处是由该方法获得的onnx模型是可以顺利转成trt模型的。<br><img src="/images/Pytorch2trt/image-1.png" style="zoom:150%;" /></p><h2 id="二、onnx-to-trt">二、onnx to trt</h2><h3 id="终端转换命令：">终端转换命令：</h3><p>Windows<br><code>.\trtexec.exe --onnx=aaa.onnx --saveEngine=retinate_hat_hair_beard_sim.trt --device=0</code><br>Ubuntu<br><code>trtexec --onnx=aaa.onnx --saveEngine=retinate_hat_hair_beard_sim.trt --device=0</code></p><h3 id="使用trt模型进行推理：">使用trt模型进行推理：</h3><pre name="code" class="python">import torchfrom torch.autograd import Variableimport tensorrt as trtimport pycuda.driver as cudafrom torchvision.utils import save_imageimport osimport pycuda.gpuarray as gpuarrayimport pycuda.autoinitfrom torchvision import datasets, transformsfrom torch.utils.data import DataLoaderfrom torchvision import transforms as Tfrom torchvision.datasets import ImageFolderimport timeimport numpy as npfrom torch.utils import dataimport torch.nn as nnimport time# 操作缓存，进行运算， 这个函数是通用的def infer(context, input_img, output_size, batch_size=1):    # Convert input data to Float32,这个类型要转换，不严会有好多报错    input_img = input_img.astype(np.float32)    # Create output array to receive data    output = np.empty(output_size, dtype=np.float32)    # output = np.empty(batch_size * output.nbytes)    # Allocate device memory    d_input = cuda.mem_alloc(batch_size * input_img.nbytes)    d_output = cuda.mem_alloc(batch_size * output.nbytes)    bindings = [int(d_input), int(d_output)]    stream = cuda.Stream()    # Transfer input data to device    cuda.memcpy_htod_async(d_input, input_img, stream)    # Execute model    context.execute_async(batch_size, bindings, stream.handle, None)    # Transfer predictions back    cuda.memcpy_dtoh_async(output, d_output, stream)    stream.synchronize()    # Return predictions    return outputclass Loader(nn.Module):    def __init__(self, image_dir, batch_size=1, num_workers=4):        super(Loader, self).__init__()        self.image_dir = image_dir        self.batch_size = batch_size        self.num_workers = num_workers    def forward(self):        transform = list()        transform.append(T.Resize([704, 1280]))  # 注意要为256的倍数        transform.append(T.ToTensor())        transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))        transform = T.Compose(transform)        dataset = ImageFolder(self.image_dir, transform)        data_loader = data.DataLoader(dataset=dataset,                                      batch_size=self.batch_size,                                      num_workers=self.num_workers)        return data_loaderdef denorm(x):    out = (x + 1) / 2    return out.clamp_(0, 1)# 执行测试函数def do_test(context, batch_size=1):    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)    test_loader = Loader(image_dir='/home/ouc/LiModel/data-paired/underwater_imagenet/val/')    print("mnist data load successful!!!")    accurary = 0    start_time = time.time()    times = []    for i, (val_img, _) in enumerate(test_loader()):    # 开始测试        # img, label = data        x_real_name = test_loader().batch_sampler.sampler.data_source.imgs[i][0]        basename = os.path.basename(x_real_name)        img = val_img.numpy()    # 这个数据要从torch.Tensor转换成numpy格式的        # print(img)        # label = Variable(label, volatile=True)        # with torch.no_grad():        #     label = Variable(label)        start_time1 = time.time()        output = infer(context, img, img.shape, 1)        end_time1 = time.time()        print(end_time1 - start_time1)        times.append((end_time1 - start_time1))        result_trt = torch.tensor(output)        # print(result_trt.shape)        # print(val_img.shape)        result = [val_img, result_trt]        result_concat1 = torch.cat(result, dim=3)        save_image((denorm(result_concat1.data.cpu())), '/home/ouc/Desktop/python/zzzzFSpiral/result/trt/' + basename, nrow=2, padding=0)        #print(output)        # conf, pred = torch.max(torch.Tensor(output), -1)        # num_count = (pred == label).sum()        # accurary += num_count.data    end_time = time.time()    print((start_time - end_time)/len(test_loader()))    print(np.mean(times))    # print("Test Acc is {:.6f}".format(accurary / len(test_dataset())))    # return accurary/len(test_dataset), time.time() - start_timedef trt_infer():    # 读取.trt文件    def loadEngine2TensorRT(filepath):        G_LOGGER = trt.Logger(trt.Logger.WARNING)        # 反序列化引擎        with open(filepath, "rb") as f, trt.Runtime(G_LOGGER) as runtime:            engine = runtime.deserialize_cuda_engine(f.read())            return engine    trt_model_name = "./resnet3.trt"    engine = loadEngine2TensorRT(trt_model_name)    # 创建上下文    context = engine.create_execution_context()    print("Start TensorRT Test...")    do_test(context)    # print('INT8 acc: {}, need time: {}'.format(acc, times))if __name__ == '__main__':    trt_infer()</pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;如果你想把你的模型投入到应用中或者是想提升模型的运行速度，除了对网络进行压缩、蒸馏外，最好的方法就是将模型转成tensor模型，使用tensorrt实现对网络的加速。但是当该模型的功能是图像增强或者是图像生成，并且模型中运用了大量的batchnorm2d函数，运用网上现成的</summary>
      
    
    
    
    
  </entry>
  
</feed>
