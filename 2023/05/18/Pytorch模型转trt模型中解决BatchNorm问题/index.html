<!DOCTYPE html><html class="appearance-light" lang="zh-CN"><head><meta charset="UTF-8"><title>Pytorchģ��תtrtģ���н��BatchNorm����</title><meta name="description" content="No Pain No Gain"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="Pytorchģ��תtrtģ�������������ģ��Ͷ�뵽Ӧ���л�����������ģ�͵������ٶȣ����˶��������ѹ���������⣬��õķ������ǽ�ģ��ת��tensorģ�ͣ�ʹ��tensorrtʵ�ֶ�����ļ��١����ǵ���ģ�͵Ĺ�����ͼ����ǿ������ͼ�����ɣ�����ģ���������˴�����batchnorm2d���������������ֳɵķ����ᷢ��ģ��ת��onnx�Լ�trt��ģ�͵Ĵ���Ч������½�������������Ϳ�����ϸ���¿��ˣ����ǵķ���˳���ǣ�pytorchģ����ת��onnxģ�ͣ����Ž�onnxģ��ת��trtģ��
һ��pytorc.."><script src="//unpkg.com/valine/dist/Valine.min.js"></script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">李祖乐's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Pytorchģ��תtrtģ���н��BatchNorm����</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">点击返回顶部</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Pytorchg%EF%BF%BD%EF%BF%BD%D7%AAtrtg%EF%BF%BD%EF%BF%BD"><span class="toc-text">Pytorchģ��תtrtģ��</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%D2%BB%EF%BF%BD%EF%BF%BDpytorch-to-onnx"><span class="toc-text">һ��pytorch to onnx</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BF%BD%EF%BF%BD%EF%BF%BDJ%EF%BF%BD%EF%BF%BD%EB%A3%BA"><span class="toc-text">���Ĵ��룺</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%D2%BB%EF%BF%BD%EF%BF%BD"><span class="toc-text">����һ��</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%CA%A9"><span class="toc-text">�����ʩ:</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BF%BD%EF%BF%BD%EF%BF%BD%D7%A3%EF%BF%BD"><span class="toc-text">���ף�</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD"><span class="toc-text">������</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%CA%A9-1"><span class="toc-text">�����ʩ:</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BF%BD%EF%BF%BD%EF%BF%BD%D7%A3%EF%BF%BD-1"><span class="toc-text">���ף�</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BDonnx-to-trt"><span class="toc-text">����onnx to trt</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BF%BD%D5%B6%EF%BF%BD%D7%AA%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EE%A3%BA"><span class="toc-text">�ն�ת�����</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%CA%B9%EF%BF%BD%EF%BF%BDtrtg%EF%BF%BD%CD%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD"><span class="toc-text">ʹ��trtģ�ͽ���������</span></a></li></ol></li></ol></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/%EF%BF%BD%EF%BF%BD%EF%BF%BD%D1%A7%CF%B0"><i class="tag post-item-tag">���ѧϰ</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">Pytorchģ��תtrtģ���н��BatchNorm����</h1><time class="has-text-grey" datetime="2023-05-18T05:08:53.000Z">2023-05-18</time><article class="mt-2 post-content"><h1 id="Pytorchg��תtrtg��"><a href="#Pytorchg��תtrtg��" class="headerlink" title="Pytorchģ��תtrtģ��"></a>Pytorchģ��תtrtģ��</h1><p>�����������ģ��Ͷ�뵽Ӧ���л�����������ģ�͵������ٶȣ����˶��������ѹ���������⣬��õķ������ǽ�ģ��ת��tensorģ�ͣ�ʹ��tensorrtʵ�ֶ�����ļ��١����ǵ���ģ�͵Ĺ�����ͼ����ǿ������ͼ�����ɣ�����ģ���������˴�����batchnorm2d���������������ֳɵķ����ᷢ��ģ��ת��onnx�Լ�trt��ģ�͵Ĵ���Ч������½�������������Ϳ�����ϸ���¿��ˣ�<br>���ǵķ���˳���ǣ�pytorchģ����ת��onnxģ�ͣ����Ž�onnxģ��ת��trtģ��</p>
<h2 id="һ��pytorch-to-onnx"><a href="#һ��pytorch-to-onnx" class="headerlink" title="һ��pytorch to onnx"></a>һ��pytorch to onnx</h2><h3 id="���J��룺"><a href="#���J��룺" class="headerlink" title="���Ĵ��룺"></a>���Ĵ��룺</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> nets.tiny_unet_2_channelxiangdeng_RCABup3_1_3 <span class="keyword">import</span> Decoder</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> ImageFolder</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="keyword">import</span> onnxruntime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Loader</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_dir, batch_size=<span class="number">1</span>, num_workers=<span class="number">4</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Loader, self).__init__()</span><br><span class="line">        self.image_dir = image_dir</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.num_workers = num_workers</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self</span>):</span><br><span class="line">        transform = <span class="built_in">list</span>()</span><br><span class="line">        transform.append(T.Resize([<span class="number">704</span>, <span class="number">1280</span>]))  <span class="comment"># ע��ҪΪ256�ı���</span></span><br><span class="line">        transform.append(T.ToTensor())</span><br><span class="line">        transform.append(T.Normalize(mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)))</span><br><span class="line"></span><br><span class="line">        transform = T.Compose(transform)</span><br><span class="line"></span><br><span class="line">        dataset = ImageFolder(self.image_dir, transform)</span><br><span class="line"></span><br><span class="line">        data_loader = data.DataLoader(dataset=dataset,</span><br><span class="line">                                      batch_size=self.batch_size,</span><br><span class="line">                                      num_workers=self.num_workers)</span><br><span class="line">        <span class="keyword">return</span> data_loader</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solver</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_loader, config</span>):</span><br><span class="line">        self.data_loader = data_loader</span><br><span class="line">        self.global_g_dim = config.global_G_ngf</span><br><span class="line">        self.device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">        self.model_save_dir = config.model_save_dir</span><br><span class="line">        self.result_dir = config.result_dir</span><br><span class="line">        self.build_model()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">restore_model</span>(<span class="params">self, resume_epoch</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Restore the trained generator and discriminator.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Loading the trained models from step &#123;&#125;...&#x27;</span>.<span class="built_in">format</span>(resume_epoch))</span><br><span class="line">        generator_path = os.path.join(self.model_save_dir, <span class="string">&#x27;&#123;&#125;-global_G.ckpt&#x27;</span>.<span class="built_in">format</span>(resume_epoch))</span><br><span class="line">        self.generator.load_state_dict(torch.load(generator_path, map_location=<span class="keyword">lambda</span> storage, loc: storage))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_model</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;create a generator and a discrimin&quot;&quot;&quot;</span></span><br><span class="line">        self.generator = Decoder(self.global_g_dim)</span><br><span class="line">        self.generator.to(self.device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">denorm</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = (x + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> out.clamp_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">to_numpy</span>(<span class="params">self, tensor</span>):</span><br><span class="line">        <span class="keyword">return</span> tensor.detach().cpu().numpy() <span class="keyword">if</span> tensor.requires_grad <span class="keyword">else</span> tensor.cpu().numpy()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">self</span>):</span><br><span class="line">        begin_epoch = <span class="number">91</span></span><br><span class="line">        end_epoch = <span class="number">92</span></span><br><span class="line">        step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(begin_epoch, end_epoch, step):</span><br><span class="line">            self.restore_model(<span class="number">94</span>)</span><br><span class="line">            self.generator.train()</span><br><span class="line">            modelData = <span class="string">&quot;../model/demo&quot;</span> + <span class="built_in">str</span>(k) + <span class="string">&quot;.onnx&quot;</span></span><br><span class="line">            <span class="comment"># modelData = &quot;demo_distok-1ok&quot; + str(k) + &quot;.onnx&quot;</span></span><br><span class="line">            data_loader = self.data_loader</span><br><span class="line">            <span class="comment"># with torch.no_grad():</span></span><br><span class="line">            <span class="keyword">for</span> i, (val_img, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):  <span class="comment"># ������ͼƬ��RGB��ʽ, ��PIL��ȡ��</span></span><br><span class="line">                <span class="keyword">if</span> i % <span class="number">50</span> != <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                x_real_name = data_loader.batch_sampler.sampler.data_source.imgs[i][<span class="number">0</span>]</span><br><span class="line">                basename = os.path.basename(x_real_name)</span><br><span class="line"></span><br><span class="line">                result_path = os.path.join(self.result_dir, <span class="built_in">str</span>(k))  <span class="comment"># ���ɵ�ͼƬ�ı����ļ���</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(result_path):</span><br><span class="line">                    os.makedirs(result_path)</span><br><span class="line"></span><br><span class="line">                result_path2 = os.path.join(result_path, basename)</span><br><span class="line">                distored_val = val_img.to(self.device)</span><br><span class="line">                clean_fake1 = self.generator(distored_val)</span><br><span class="line">                torch.cuda.synchronize()</span><br><span class="line">                clean_fake1 = clean_fake1.data.cpu()</span><br><span class="line">                save_image(self.denorm(clean_fake1), result_path2, nrow=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                torch.onnx.export(self.generator, distored_val, modelData, opset_version=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">                onnx_model = onnx.load(modelData)</span><br><span class="line">                onnx.checker.check_model(onnx_model)</span><br><span class="line">                ort_session = onnxruntime.InferenceSession(modelData,</span><br><span class="line">                                                            providers=[<span class="string">&#x27;CUDAExecutionProvider&#x27;</span>])</span><br><span class="line">                ort_inputs = &#123;ort_session.get_inputs()[<span class="number">0</span>].name: self.to_numpy(distored_val)&#125;</span><br><span class="line">                ort_outs = ort_session.run(<span class="literal">None</span>, ort_inputs)</span><br><span class="line">                result_path1 = os.path.join(self.result_dir, <span class="string">&quot;trt&quot;</span>+<span class="built_in">str</span>(k))</span><br><span class="line">                result_pathtrt = os.path.join(result_path1, basename)</span><br><span class="line">                <span class="comment">#save_image((self.denorm(torch.tensor(ort_outs[0]))),result_pathtrt, nrow=1, padding=0)</span></span><br><span class="line"></span><br><span class="line">                result = [val_img, torch.tensor(ort_outs[<span class="number">0</span>]), clean_fake1]</span><br><span class="line">                result_concat1 = torch.cat(result, dim=<span class="number">3</span>)</span><br><span class="line">                <span class="comment"># break</span></span><br><span class="line">                save_image((self.denorm(result_concat1.data.cpu())), result_path2, nrow=<span class="number">2</span>, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">config</span>):</span><br><span class="line">    data_loader = Loader(config.data_dir)</span><br><span class="line">    solver = Solver(data_loader(), config)</span><br><span class="line">    solver.test()</span><br><span class="line">    <span class="comment">#solver.build_model()</span></span><br><span class="line">    <span class="comment">#solver.printnetwork()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--global_G_ngf&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">16</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of conv filters in the first layer of G&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_workers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">r&#x27;D:\Data\Paired\underwater_imagenet\val&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--model_save_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="comment">#default=&#x27;/home/ouc/Li/Torch2TRT/trt_outfile/model&#x27;</span></span><br><span class="line">                        default=<span class="string">r&#x27;C:\TensorRT-8.6.0.12\samples\python\zzzzFSpiral\modules&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--result_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">r&#x27;C:\TensorRT-8.6.0.12\samples\python\zzzzFSpiral\result&#x27;</span>)</span><br><span class="line">    torch.cuda.set_device(<span class="number">0</span>)</span><br><span class="line">    config = parser.parse_args()</span><br><span class="line">    main(config)</span><br></pre></td></tr></table></figure>
<p>��pytorchת��onnxʱ����Ҫ��ģ�ͽ���evalģʽ����Ϊ��PyTorch�У�ģ��ѵ����������inference��������ģʽ��ѵ��ģʽ������ģʽ��evaluation mode������ѵ��ģʽ�£�ģ�ͻᱣ��һЩ�м������Ա���з��򴫲��Ͳ�������(��batchnorm2d��train��evalģ���еļ��㲻һ�£��漰���ڲ��ı���running_mean��running_eval�ļ��㣨����ͼ��ʾ��)����������ģʽ�£�ģ�Ͳ��ᱣ����Щ�м������Ա������������ˣ��ڽ�PyTorchģ��ת��ΪONNXģ��ʱ����Ҫ��ģ���л�������ģʽ����ȷ��ģ�͵�������������һ�¡������ת��ģ��֮ǰ����ģ���л�������ģʽ�����ܻᵼ��ת�����ONNXģ�������Ԥ�ڲ�һ�¡���ˣ�Ϊ��ȷ��ת�����ONNXģ�͵���ȷ�ԣ���Ҫ��PyTorchģ���л�������ģʽ��eval mode���ٽ���ת����</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyBatchNorm2d</span>(nn.BatchNorm2d):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, eps=<span class="number">1e-5</span>, momentum=<span class="number">0.1</span>,</span></span><br><span class="line"><span class="params">                 affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MyBatchNorm2d, self).__init__(</span><br><span class="line">            num_features, eps, momentum, affine, track_running_stats)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        self._check_input_dim(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">        exponential_average_factor = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.track_running_stats:</span><br><span class="line">            <span class="keyword">if</span> self.num_batches_tracked <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                self.num_batches_tracked += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> self.momentum <span class="keyword">is</span> <span class="literal">None</span>:  <span class="comment"># use cumulative moving average</span></span><br><span class="line">                    exponential_average_factor = <span class="number">1.0</span> / <span class="built_in">float</span>(self.num_batches_tracked)</span><br><span class="line">                <span class="keyword">else</span>:  <span class="comment"># use exponential moving average</span></span><br><span class="line">                    exponential_average_factor = self.momentum</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate running estimates</span></span><br><span class="line">        <span class="keyword">if</span> self.training:</span><br><span class="line">            mean = <span class="built_in">input</span>.mean([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">            <span class="comment"># use biased var in train</span></span><br><span class="line">            var = <span class="built_in">input</span>.var([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>], unbiased=<span class="literal">False</span>)</span><br><span class="line">            n = <span class="built_in">input</span>.numel() / <span class="built_in">input</span>.size(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                self.running_mean = exponential_average_factor * mean\</span><br><span class="line">                    + (<span class="number">1</span> - exponential_average_factor) * self.running_mean</span><br><span class="line">                <span class="comment"># update running_var with unbiased var</span></span><br><span class="line">                self.running_var = exponential_average_factor * var * n / (n - <span class="number">1</span>)\</span><br><span class="line">                    + (<span class="number">1</span> - exponential_average_factor) * self.running_var</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mean = self.running_mean</span><br><span class="line">            var = self.running_var</span><br><span class="line"></span><br><span class="line">        <span class="built_in">input</span> = (<span class="built_in">input</span> - mean[<span class="literal">None</span>, :, <span class="literal">None</span>, <span class="literal">None</span>]) / (torch.sqrt(var[<span class="literal">None</span>, :, <span class="literal">None</span>, <span class="literal">None</span>] + self.eps))</span><br><span class="line">        <span class="keyword">if</span> self.affine:</span><br><span class="line">            <span class="built_in">input</span> = <span class="built_in">input</span> * self.weight[<span class="literal">None</span>, :, <span class="literal">None</span>, <span class="literal">None</span>] + self.bias[<span class="literal">None</span>, :, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">input</span></span><br></pre></td></tr></table></figure>

<p>��ģ����trainʱ����<code>mean = input.mean([0, 2, 3])��var = input.var([0, 2, 3], unbiased=False)</code>�������뵱ǰ��������ҹ������ǵ�ģ����evalģʽʱ����<code>mean = self.running_mean��var = self.running_var</code>�������뵱ǰ�������޹أ����ǽ�ѧϰ����running_mean��running_varֱ����Ϊ��ǰ�����mean��var�����ڸ�ѧϰ�õ��ľ�ֵ�뷽�running_mean��running_var����������ȫ�������е��������������ģ����evalģʽ�µĴ���Ч�����󽵵͡�</p>
<p>�������˿��ܻ���Ϊʲôģ��ת��onnxʱҪ��ģ������Ϊevalģʽ��ֱ������Ϊtrainģʽ���Ϳ��Խ������Ч���½����������𣿵��ǵ��㰴���뷨ʵ���ʱ�򣬻ᷢ����Ȼpytorchģ�͵Ĵ���Ч��û���⣬����onnxģ�͵Ĵ���Ч������һ���Ĳ������Ϊʲô�أ��ҵĲ²���onnxģ��������ʱĬ�Ͻ�batchnorm��ģʽ����Ϊeval����������Ľ���ʹ��������ˡ�������Ҹ��˵��뷨������в�ͬ������Ի��ཻ����</p>
<p>�������ڵ������ת���������ʹģ����evalģʽ�¼����mean��var�͵�ǰ������أ�����������ѧϰ����running_mean��running_eval�������˿���������������޴������ˣ���Ϊ���������޷�����ġ�����������������������ܽ���ġ����Ⱦ����������������������Ҷ���������Ѿ��ǱȽ�����ˡ�</p>
<p>�������ҽ��������ֺܼ򵥵ķ��������onnxģ�ʹ���Ч��������⣺</p>
<h3 id="����һ��"><a href="#����һ��" class="headerlink" title="����һ��"></a>����һ��</h3><h5 id="�����ʩ"><a href="#�����ʩ" class="headerlink" title="�����ʩ:"></a>�����ʩ:</h5><p>�޸�batchnorm2d�е�Դ�룬��if self.training���Ϸ���һ��self.training &#x3D;True���������ܴ���evalģʽ������batchnorm��Ȼ�Ǵ���ѵ��״̬�ģ�����������£�mean��var��Ȼ�ͺ�input�ҹ��ˡ�</p>
<img src="Pytorch2trt\image-20230514162311051.png" style="zoom: 200%;" />

<h5 id="���ף�"><a href="#���ף�" class="headerlink" title="���ף�"></a>���ף�</h5><p>�������ַ�����Ȼ���Խ��onnxģ�ʹ���Ч��������⣬�����ɸ÷�����õ�onnxģ�����޷��ɹ�תtensorrt�ġ�ԭ������Ϊonnxģ�͵Ĳ������ǹ̶����ģ�������������չʾ�Ĵ����У���ģ�ʹ���ѵ��ģʽʱ��running_mean��running_var�Ǳ仯�ģ���˻�õ�onnx�������û���⣬�����ڲ��Ǵ�������ġ�<br>batchnorm2d��Դ����·������:</p>
<p><code>C:\Users\Spring\Anaconda3\envs\torchli\Lib\site-packages\torch\nn\modules\batchnorm.py</code></p>
<h3 id="������"><a href="#������" class="headerlink" title="������"></a>������</h3><h5 id="�����ʩ-1"><a href="#�����ʩ-1" class="headerlink" title="�����ʩ:"></a>�����ʩ:</h5><p>�޸�batchnorm2d��Դ�룬�����뷽��һ�������𣬾����޸ļ���ͼ��֮���������޸�����Ϊbatchnorm��evalģʽ�£�mean��var��running_mean��running_val�ҹ�����������ǰ��ѧϰ����running_mean��running_var���ó���input�ҹ���Ȼ���mean��var�ͺ�input��ϵ�����ˡ�</p>
<h5 id="���ף�-1"><a href="#���ף�-1" class="headerlink" title="���ף�"></a>���ף�</h5><p>�������ַ�����Ȼ���Խ��onnxģ�ʹ���Ч��������⣬���ǵ����ӻ��ɸ÷�����õ�onnxģ��ʱ���ᷢ��batchnorm�ǲ������ģ��Ϸ�����һЩ�����֧������ͼ��ʾ�������Ƿ���һ��batchnorm�Ǵ����ģ�����ͼ��ʾ�����ô����ɸ÷�����õ�onnxģ���ǿ���˳��ת��trtģ�͵ġ�</p>
<p><img src="Pytorch2trt\clip_image001.png" style="zoom:150%;" /><img src="Pytorch2trt\clip_image003.png"  /></p>
<h2 id="����onnx-to-trt"><a href="#����onnx-to-trt" class="headerlink" title="����onnx to trt"></a>����onnx to trt</h2><h3 id="�ն�ת�����"><a href="#�ն�ת�����" class="headerlink" title="�ն�ת�����"></a>�ն�ת�����</h3><p>Windows<br><code>.\trtexec.exe --onnx=aaa.onnx --saveEngine=retinate_hat_hair_beard_sim.trt --device=0</code><br>Ubuntu<br><code>trtexec --onnx=aaa.onnx --saveEngine=retinate_hat_hair_beard_sim.trt --device=0</code></p>
<h3 id="ʹ��trtg�ͽ���������"><a href="#ʹ��trtg�ͽ���������" class="headerlink" title="ʹ��trtģ�ͽ���������"></a>ʹ��trtģ�ͽ���������</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> tensorrt <span class="keyword">as</span> trt</span><br><span class="line"><span class="keyword">import</span> pycuda.driver <span class="keyword">as</span> cuda</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pycuda.gpuarray <span class="keyword">as</span> gpuarray</span><br><span class="line"><span class="keyword">import</span> pycuda.autoinit</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> ImageFolder</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># �������棬�������㣬 ���������ͨ�õ�</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">infer</span>(<span class="params">context, input_img, output_size, batch_size=<span class="number">1</span></span>):</span><br><span class="line">    <span class="comment"># Convert input data to Float32,�������Ҫת�������ϻ��кö౨��</span></span><br><span class="line">    input_img = input_img.astype(np.float32)</span><br><span class="line">    <span class="comment"># Create output array to receive data</span></span><br><span class="line">    output = np.empty(output_size, dtype=np.float32)</span><br><span class="line">    <span class="comment"># output = np.empty(batch_size * output.nbytes)</span></span><br><span class="line">    <span class="comment"># Allocate device memory</span></span><br><span class="line">    d_input = cuda.mem_alloc(batch_size * input_img.nbytes)</span><br><span class="line">    d_output = cuda.mem_alloc(batch_size * output.nbytes)</span><br><span class="line"></span><br><span class="line">    bindings = [<span class="built_in">int</span>(d_input), <span class="built_in">int</span>(d_output)]</span><br><span class="line"></span><br><span class="line">    stream = cuda.Stream()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Transfer input data to device</span></span><br><span class="line">    cuda.memcpy_htod_async(d_input, input_img, stream)</span><br><span class="line">    <span class="comment"># Execute model</span></span><br><span class="line">    context.execute_async(batch_size, bindings, stream.handle, <span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># Transfer predictions back</span></span><br><span class="line">    cuda.memcpy_dtoh_async(output, d_output, stream)</span><br><span class="line"></span><br><span class="line">    stream.synchronize()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return predictions</span></span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Loader</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_dir, batch_size=<span class="number">1</span>, num_workers=<span class="number">4</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Loader, self).__init__()</span><br><span class="line">        self.image_dir = image_dir</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.num_workers = num_workers</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self</span>):</span><br><span class="line">        transform = <span class="built_in">list</span>()</span><br><span class="line">        transform.append(T.Resize([<span class="number">704</span>, <span class="number">1280</span>]))  <span class="comment"># ע��ҪΪ256�ı���</span></span><br><span class="line">        transform.append(T.ToTensor())</span><br><span class="line">        transform.append(T.Normalize(mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)))</span><br><span class="line"></span><br><span class="line">        transform = T.Compose(transform)</span><br><span class="line"></span><br><span class="line">        dataset = ImageFolder(self.image_dir, transform)</span><br><span class="line"></span><br><span class="line">        data_loader = data.DataLoader(dataset=dataset,</span><br><span class="line">                                      batch_size=self.batch_size,</span><br><span class="line">                                      num_workers=self.num_workers)</span><br><span class="line">        <span class="keyword">return</span> data_loader</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">denorm</span>(<span class="params">x</span>):</span><br><span class="line">    out = (x + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> out.clamp_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ִ�в��Ժ���</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_test</span>(<span class="params">context, batch_size=<span class="number">1</span></span>):</span><br><span class="line">    <span class="comment"># train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)</span></span><br><span class="line">    test_loader = Loader(image_dir=<span class="string">&#x27;/home/ouc/LiModel/data-paired/underwater_imagenet/val/&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;mnist data load successful!!!&quot;</span>)</span><br><span class="line">    accurary = <span class="number">0</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    times = []</span><br><span class="line">    <span class="keyword">for</span> i, (val_img, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):    <span class="comment"># ��ʼ����</span></span><br><span class="line">        <span class="comment"># img, label = data</span></span><br><span class="line">        x_real_name = test_loader().batch_sampler.sampler.data_source.imgs[i][<span class="number">0</span>]</span><br><span class="line">        basename = os.path.basename(x_real_name)</span><br><span class="line">        img = val_img.numpy()    <span class="comment"># �������Ҫ��torch.Tensorת����numpy��ʽ��</span></span><br><span class="line">        <span class="comment"># print(img)</span></span><br><span class="line">        <span class="comment"># label = Variable(label, volatile=True)</span></span><br><span class="line">        <span class="comment"># with torch.no_grad():</span></span><br><span class="line">        <span class="comment">#     label = Variable(label)</span></span><br><span class="line">        start_time1 = time.time()</span><br><span class="line">        output = infer(context, img, img.shape, <span class="number">1</span>)</span><br><span class="line">        end_time1 = time.time()</span><br><span class="line">        <span class="built_in">print</span>(end_time1 - start_time1)</span><br><span class="line">        times.append((end_time1 - start_time1))</span><br><span class="line">        result_trt = torch.tensor(output)</span><br><span class="line">        <span class="comment"># print(result_trt.shape)</span></span><br><span class="line">        <span class="comment"># print(val_img.shape)</span></span><br><span class="line">        result = [val_img, result_trt]</span><br><span class="line">        result_concat1 = torch.cat(result, dim=<span class="number">3</span>)</span><br><span class="line">        save_image((denorm(result_concat1.data.cpu())), <span class="string">&#x27;/home/ouc/Desktop/python/zzzzFSpiral/result/trt/&#x27;</span> + basename, nrow=<span class="number">2</span>, padding=<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#print(output)</span></span><br><span class="line">        <span class="comment"># conf, pred = torch.max(torch.Tensor(output), -1)</span></span><br><span class="line">        <span class="comment"># num_count = (pred == label).sum()</span></span><br><span class="line">        <span class="comment"># accurary += num_count.data</span></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    <span class="built_in">print</span>((start_time - end_time)/<span class="built_in">len</span>(test_loader()))</span><br><span class="line">    <span class="built_in">print</span>(np.mean(times))</span><br><span class="line">    <span class="comment"># print(&quot;Test Acc is &#123;:.6f&#125;&quot;.format(accurary / len(test_dataset())))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># return accurary/len(test_dataset), time.time() - start_time</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">trt_infer</span>():</span><br><span class="line">    <span class="comment"># ��ȡ.trt�ļ�</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loadEngine2TensorRT</span>(<span class="params">filepath</span>):</span><br><span class="line">        G_LOGGER = trt.Logger(trt.Logger.WARNING)</span><br><span class="line">        <span class="comment"># �����л�����</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filepath, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f, trt.Runtime(G_LOGGER) <span class="keyword">as</span> runtime:</span><br><span class="line">            engine = runtime.deserialize_cuda_engine(f.read())</span><br><span class="line">            <span class="keyword">return</span> engine</span><br><span class="line"></span><br><span class="line">    trt_model_name = <span class="string">&quot;./resnet3.trt&quot;</span></span><br><span class="line">    engine = loadEngine2TensorRT(trt_model_name)</span><br><span class="line">    <span class="comment"># ����������</span></span><br><span class="line">    context = engine.create_execution_context()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Start TensorRT Test...&quot;</span>)</span><br><span class="line">    do_test(context)</span><br><span class="line">    <span class="comment"># print(&#x27;INT8 acc: &#123;&#125;, need time: &#123;&#125;&#x27;.format(acc, times))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    trt_infer()</span><br></pre></td></tr></table></figure>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><em></em><a class="button is-default" href="/2023/05/17/hello-world/" title="Hello World"><span class="has-text-weight-semibold">下一页: Hello World</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Sprli/Sprli.github.io" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article><article class="mt-6 comment-container" id="vcomments"></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/Sprli"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> 李祖乐 2023</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>